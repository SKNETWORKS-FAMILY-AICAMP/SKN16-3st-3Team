{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai gradio langchain langchain-community langchain-openai chromadb pypdf tiktoken pillow python-dotenv bcrypt pandas openpyxl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEPj_-E40lx-",
        "outputId": "745e4886-96c2-4847-95e5-76bb30193dda",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.107.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.44.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.3.29)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (0.3.33)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.0.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: bcrypt in /usr/local/lib/python3.12/dist-packages (4.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.12.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.12.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.34.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.12)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.17.4)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.76)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.5)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.4.2)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.4.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.22.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.74.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (33.1.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.2.0)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.19.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.9)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.58b0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "ì±—ë¬¸ì² (ChatMoonCheol) - í•œë¬¸ì²  AI êµí†µë²• ìƒë‹´ ì±—ë´‡ ì™„ì „ ê°œì„ íŒ\n",
        "- ëª¨ë˜í•œ í•„ë › ì•„ì´ì½˜ ë””ìì¸\n",
        "- ê°„ì†Œí™”ëœ ë¡œê·¸ì¸ ì„¸ì…˜\n",
        "- ê°œì„ ëœ ë¬¸ì„œ ê´€ë¦¬\n",
        "- ë¯¸ë‹ˆë©€í•œ AI ìƒë‹´ ì¸í„°í˜ì´ìŠ¤\n",
        "\n",
        "ğŸ”§ ì£¼ìš” ìˆ˜ì • ì‚¬í•­:\n",
        "âœ… AI ìƒë‹´: í•„ë › ì•„ì´ì½˜ ê¸°ë°˜ ëª¨ë˜ ë””ìì¸\n",
        "âœ… ë¬¸ì„œ ê´€ë¦¬: ì—…ë¡œë“œ ì§„í–‰ë¥  ì‚­ì œ, íŒŒì¼ ìœ ì§€ ê¸°ëŠ¥\n",
        "âœ… ë¡œê·¸ì¸: ì„¤ëª… í…ìŠ¤íŠ¸ ì‚­ì œ, ê· í˜•ìˆëŠ” ë°°ì¹˜\n",
        "âœ… UI/UX: ë¯¸ë‹ˆë©€í•˜ê³  ì§ê´€ì ì¸ ì¸í„°í˜ì´ìŠ¤\n",
        "\n",
        "ì‹¤í–‰: python chatmooncheol_redesigned.py\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import base64\n",
        "import sqlite3\n",
        "import uuid\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import io\n",
        "import shutil\n",
        "import chardet\n",
        "import threading\n",
        "import time\n",
        "import re\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any, Optional, Tuple, Generator\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "def install_packages():\n",
        "    required = [\n",
        "        'openai>=1.12.0', 'gradio>=4.18.0', 'langchain>=0.1.10',\n",
        "        'langchain-community>=0.0.25', 'langchain-openai>=0.0.6',\n",
        "        'chromadb>=0.4.22', 'pypdf>=4.0.1', 'tiktoken>=0.6.0',\n",
        "        'Pillow>=10.2.0', 'python-dotenv>=1.0.1', 'bcrypt>=4.0.1',\n",
        "        'pandas>=2.0.0', 'openpyxl>=3.1.0', 'chardet>=5.0.0',\n",
        "        'python-docx>=0.8.11', 'unidecode>=1.3.0'\n",
        "    ]\n",
        "    import subprocess\n",
        "    print(\"ğŸ“¦ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘...\")\n",
        "    for package in required:\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package],\n",
        "                                stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "            print(f\"âœ… {package}\")\n",
        "        except:\n",
        "            print(f\"âš ï¸ {package} ì„¤ì¹˜ ì‹¤íŒ¨\")\n",
        "\n",
        "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
        "try:\n",
        "    import openai\n",
        "    import gradio as gr\n",
        "    from dotenv import load_dotenv\n",
        "    import chromadb\n",
        "    from PIL import Image\n",
        "    import bcrypt\n",
        "    import chardet\n",
        "    from pathlib import Path\n",
        "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "    from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
        "    from langchain_openai import OpenAIEmbeddings\n",
        "    from langchain_community.vectorstores import Chroma\n",
        "    from langchain.schema import Document\n",
        "\n",
        "    # ì„ íƒì  ì„í¬íŠ¸\n",
        "    try:\n",
        "        from docx import Document as DocxDocument\n",
        "        DOCX_AVAILABLE = True\n",
        "    except ImportError:\n",
        "        DOCX_AVAILABLE = False\n",
        "        print(\"ğŸ“Œ python-docx ì—†ìŒ: DOCX íŒŒì¼ ì§€ì› ì œí•œ\")\n",
        "\n",
        "except ImportError as e:\n",
        "    print(f\"âŒ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}\")\n",
        "    install_packages()\n",
        "    print(\"ğŸ”„ ì¬ì‹œì‘ í•„ìš”!\")\n",
        "    sys.exit(1)\n",
        "\n",
        "load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Q5JNbjkf5Lz",
        "outputId": "6407fcc3-6865-4992-d16c-993ab5d3dfa7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Œ python-docx ì—†ìŒ: DOCX íŒŒì¼ ì§€ì› ì œí•œ\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 978
        },
        "id": "yi1Gs7aFQAf8",
        "outputId": "91645e99-bdd9-4396-8798-654c44e59e94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš–ï¸ ì±—ë¬¸ì²  ì™„ì „ ê°œì„ íŒ ì‹œìŠ¤í…œ ì‹œì‘\n",
            "============================================================\n",
            "ğŸ”‘ OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”: 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\n",
            "âœ… RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ\n",
            "âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!\n",
            "ğŸŒ ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:7860 ì ‘ì†\n",
            "\n",
            "ğŸ” ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ê³„ì •:\n",
            "  ê²ŒìŠ¤íŠ¸: guest / guest123\n",
            "  ì „ë¬¸ê°€: expert / expert123\n",
            "  ê´€ë¦¬ì: admin / admin123\n",
            "\n",
            "ğŸ¨ ì™„ì „ ê°œì„  ì‚¬í•­:\n",
            "  âœ… ëª¨ë˜í•œ í•„ë › ì•„ì´ì½˜ ë””ìì¸\n",
            "  âœ… ê°„ì†Œí™”ëœ ë¡œê·¸ì¸ í˜ì´ì§€\n",
            "  âœ… AI ìƒë‹´: ì‚¬ì´ë“œë°” ì•„ì´ì½˜ + ì…ë ¥/ì „ì†¡ ê°œì„ \n",
            "  âœ… ë¬¸ì„œ ê´€ë¦¬: ì§„í–‰ë¥  ì‚­ì œ + íŒŒì¼ ìœ ì§€\n",
            "  âœ… ë°˜ì„±ë¬¸/í•©ì˜ì¡°ì–¸ ë²„íŠ¼ ì‚­ì œ\n",
            "  âœ… ì „ì²´ì ì¸ UI/UX í–¥ìƒ\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://b4fc6fc05c9c71f4c1.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b4fc6fc05c9c71f4c1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# (ì´ì „ í´ë˜ìŠ¤ ì •ì˜ë“¤ì€ ë™ì¼í•˜ë¯€ë¡œ ìƒëµ)\n",
        "\n",
        "class DatabaseManager:\n",
        "    \"\"\"í†µí•© ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬\"\"\"\n",
        "    def __init__(self, db_path=\"chatmooncheol_redesigned.db\"):\n",
        "        self.db_path = db_path\n",
        "        self._init_database()\n",
        "\n",
        "    def _init_database(self):\n",
        "        with sqlite3.connect(self.db_path) as conn:\n",
        "            cursor = conn.cursor()\n",
        "\n",
        "            # ì‚¬ìš©ì í…Œì´ë¸”\n",
        "            cursor.execute(\"\"\"\n",
        "                CREATE TABLE IF NOT EXISTS users (\n",
        "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                    username TEXT UNIQUE NOT NULL,\n",
        "                    password_hash TEXT NOT NULL,\n",
        "                    user_type TEXT NOT NULL CHECK(user_type IN ('guest', 'expert', 'admin')),\n",
        "                    email TEXT,\n",
        "                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
        "                    last_login DATETIME\n",
        "                )\"\"\")\n",
        "\n",
        "            # ëŒ€í™” ì„¸ì…˜ í…Œì´ë¸”\n",
        "            cursor.execute(\"\"\"\n",
        "                CREATE TABLE IF NOT EXISTS conversations (\n",
        "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                    user_id INTEGER,\n",
        "                    session_id TEXT UNIQUE NOT NULL,\n",
        "                    title TEXT DEFAULT 'ìƒˆ ìƒë‹´',\n",
        "                    started_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
        "                    ended_at DATETIME,\n",
        "                    total_messages INTEGER DEFAULT 0,\n",
        "                    case_summary TEXT,\n",
        "                    FOREIGN KEY (user_id) REFERENCES users(id)\n",
        "                )\"\"\")\n",
        "\n",
        "            # ë©”ì‹œì§€ í…Œì´ë¸”\n",
        "            cursor.execute(\"\"\"\n",
        "                CREATE TABLE IF NOT EXISTS messages (\n",
        "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                    conversation_id INTEGER,\n",
        "                    role TEXT NOT NULL CHECK(role IN ('user', 'assistant')),\n",
        "                    content TEXT NOT NULL,\n",
        "                    message_type TEXT DEFAULT 'normal',\n",
        "                    image_data TEXT,\n",
        "                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
        "                    FOREIGN KEY (conversation_id) REFERENCES conversations(id)\n",
        "                )\"\"\")\n",
        "\n",
        "            # ì‚¬ê±´ ë¶„ì„ í…Œì´ë¸”\n",
        "            cursor.execute(\"\"\"\n",
        "                CREATE TABLE IF NOT EXISTS case_analysis (\n",
        "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                    conversation_id INTEGER,\n",
        "                    case_type TEXT CHECK(case_type IN ('criminal', 'civil', 'consultation', 'mixed')),\n",
        "                    accident_type TEXT,\n",
        "                    fault_ratio TEXT,\n",
        "                    severity_level TEXT CHECK(severity_level IN ('minor', 'moderate', 'severe')),\n",
        "                    legal_violations TEXT,\n",
        "                    recommended_actions TEXT,\n",
        "                    party_role TEXT CHECK(party_role IN ('perpetrator', 'victim', 'witness', 'neutral')),\n",
        "                    settlement_amount INTEGER DEFAULT 0,\n",
        "                    apology_needed BOOLEAN DEFAULT FALSE,\n",
        "                    applicable_laws TEXT,\n",
        "                    fine_amount INTEGER DEFAULT 0,\n",
        "                    imprisonment_period TEXT,\n",
        "                    driver_license_points INTEGER DEFAULT 0,\n",
        "                    analysis_confidence REAL DEFAULT 0.0,\n",
        "                    raw_analysis_json TEXT,\n",
        "                    analyzed_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
        "                    FOREIGN KEY (conversation_id) REFERENCES conversations(id)\n",
        "                )\"\"\")\n",
        "\n",
        "            # RAG ë¬¸ì„œ í…Œì´ë¸”\n",
        "            cursor.execute(\"\"\"\n",
        "                CREATE TABLE IF NOT EXISTS documents (\n",
        "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                    filename TEXT NOT NULL,\n",
        "                    original_filename TEXT NOT NULL,\n",
        "                    file_type TEXT NOT NULL,\n",
        "                    file_size INTEGER,\n",
        "                    encoding TEXT,\n",
        "                    uploaded_by INTEGER,\n",
        "                    upload_date DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
        "                    processed BOOLEAN DEFAULT FALSE,\n",
        "                    chunk_count INTEGER DEFAULT 0,\n",
        "                    processing_status TEXT DEFAULT 'pending',\n",
        "                    error_message TEXT,\n",
        "                    processing_time REAL DEFAULT 0.0,\n",
        "                    file_hash TEXT,\n",
        "                    FOREIGN KEY (uploaded_by) REFERENCES users(id)\n",
        "                )\"\"\")\n",
        "\n",
        "            # ë¬¸ì„œ ì²­í¬ ë©”íƒ€ë°ì´í„° í…Œì´ë¸”\n",
        "            cursor.execute(\"\"\"\n",
        "                CREATE TABLE IF NOT EXISTS document_chunks (\n",
        "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                    document_id INTEGER,\n",
        "                    chunk_index INTEGER,\n",
        "                    chunk_text TEXT,\n",
        "                    chunk_size INTEGER,\n",
        "                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
        "                    FOREIGN KEY (document_id) REFERENCES documents(id)\n",
        "                )\"\"\")\n",
        "\n",
        "            conn.commit()\n",
        "        self._create_default_users()\n",
        "\n",
        "    def _create_default_users(self):\n",
        "        \"\"\"ê¸°ë³¸ ì‚¬ìš©ì ìƒì„±\"\"\"\n",
        "        users = [\n",
        "            (\"admin\", \"admin123\", \"admin\", \"admin@chatmooncheol.com\"),\n",
        "            (\"expert\", \"expert123\", \"expert\", \"expert@chatmooncheol.com\"),\n",
        "            (\"guest\", \"guest123\", \"guest\", \"guest@chatmooncheol.com\")\n",
        "        ]\n",
        "        for username, password, user_type, email in users:\n",
        "            self.create_user(username, password, user_type, email)\n",
        "\n",
        "    def create_user(self, username: str, password: str, user_type: str, email: str = None) -> bool:\n",
        "        try:\n",
        "            password_hash = bcrypt.hashpw(password.encode('utf-8'), bcrypt.gensalt())\n",
        "            with sqlite3.connect(self.db_path) as conn:\n",
        "                cursor = conn.cursor()\n",
        "                cursor.execute(\"\"\"\n",
        "                    INSERT OR IGNORE INTO users (username, password_hash, user_type, email)\n",
        "                    VALUES (?, ?, ?, ?)\n",
        "                \"\"\", (username, password_hash.decode('utf-8'), user_type, email))\n",
        "                return cursor.rowcount > 0\n",
        "        except:\n",
        "            return False\n",
        "\n",
        "    def authenticate(self, username: str, password: str) -> Optional[Dict]:\n",
        "        try:\n",
        "            with sqlite3.connect(self.db_path) as conn:\n",
        "                cursor = conn.cursor()\n",
        "                cursor.execute(\"SELECT id, username, password_hash, user_type, email FROM users WHERE username = ?\", (username,))\n",
        "                user = cursor.fetchone()\n",
        "                if user and bcrypt.checkpw(password.encode('utf-8'), user[2].encode('utf-8')):\n",
        "                    cursor.execute(\"UPDATE users SET last_login = CURRENT_TIMESTAMP WHERE id = ?\", (user[0],))\n",
        "                    conn.commit()\n",
        "                    return {'id': user[0], 'username': user[1], 'user_type': user[3], 'email': user[4]}\n",
        "        except:\n",
        "            pass\n",
        "        return None\n",
        "\n",
        "    def create_conversation(self, user_id: int, title: str = \"ìƒˆ ìƒë‹´\") -> str:\n",
        "        session_id = str(uuid.uuid4())\n",
        "        try:\n",
        "            with sqlite3.connect(self.db_path) as conn:\n",
        "                cursor = conn.cursor()\n",
        "                cursor.execute(\"INSERT INTO conversations (user_id, session_id, title) VALUES (?, ?, ?)\",\n",
        "                               (user_id, session_id, title))\n",
        "                return session_id\n",
        "        except:\n",
        "            return str(uuid.uuid4())\n",
        "\n",
        "    def save_message(self, session_id: str, role: str, content: str, message_type: str = \"normal\", image_data: str = None):\n",
        "        try:\n",
        "            with sqlite3.connect(self.db_path) as conn:\n",
        "                cursor = conn.cursor()\n",
        "                cursor.execute(\"SELECT id FROM conversations WHERE session_id = ?\", (session_id,))\n",
        "                conv = cursor.fetchone()\n",
        "                if conv:\n",
        "                    cursor.execute(\"\"\"\n",
        "                        INSERT INTO messages (conversation_id, role, content, message_type, image_data)\n",
        "                        VALUES (?, ?, ?, ?, ?)\n",
        "                    \"\"\", (conv[0], role, content, message_type, image_data))\n",
        "                    cursor.execute(\"UPDATE conversations SET total_messages = total_messages + 1 WHERE id = ?\", (conv[0],))\n",
        "                    conn.commit()\n",
        "                    return True\n",
        "        except Exception as e:\n",
        "            print(f\"ë©”ì‹œì§€ ì €ì¥ ì˜¤ë¥˜: {e}\")\n",
        "            return False\n",
        "\n",
        "    def save_analysis(self, session_id: str, analysis: Dict):\n",
        "        \"\"\"ë¶„ì„ ê²°ê³¼ë¥¼ DBì— ì €ì¥\"\"\"\n",
        "        try:\n",
        "            with sqlite3.connect(self.db_path) as conn:\n",
        "                cursor = conn.cursor()\n",
        "                cursor.execute(\"SELECT id FROM conversations WHERE session_id = ?\", (session_id,))\n",
        "                conv = cursor.fetchone()\n",
        "                if conv:\n",
        "                    # ê¸°ë³¸ê°’ ì„¤ì • ë° ë°ì´í„° ê²€ì¦\n",
        "                    case_type = analysis.get('case_type', 'consultation')\n",
        "                    accident_type = analysis.get('accident_type', 'ê¸°íƒ€')\n",
        "                    fault_ratio = analysis.get('fault_ratio', 'ë¯¸ì •')\n",
        "                    severity_level = analysis.get('severity_level', 'minor')\n",
        "                    party_role = analysis.get('party_role', 'neutral')\n",
        "\n",
        "                    # ë¦¬ìŠ¤íŠ¸ íƒ€ì… ë°ì´í„° JSON ë³€í™˜\n",
        "                    legal_violations = json.dumps(analysis.get('legal_violations', []), ensure_ascii=False)\n",
        "                    recommended_actions = json.dumps(analysis.get('recommended_actions', []), ensure_ascii=False)\n",
        "                    applicable_laws = json.dumps(analysis.get('applicable_laws', []), ensure_ascii=False)\n",
        "\n",
        "                    # ìˆ«ì íƒ€ì… ë°ì´í„° ê²€ì¦\n",
        "                    settlement_amount = self._safe_int(analysis.get('settlement_amount', 0))\n",
        "                    fine_amount = self._safe_int(analysis.get('fine_amount', 0))\n",
        "                    driver_license_points = self._safe_int(analysis.get('driver_license_points', 0))\n",
        "                    analysis_confidence = self._safe_float(analysis.get('confidence', 0.0))\n",
        "\n",
        "                    # ë¶ˆë¦° íƒ€ì… ë°ì´í„° ê²€ì¦\n",
        "                    apology_needed = bool(analysis.get('apology_needed', False))\n",
        "\n",
        "                    # ë¬¸ìì—´ íƒ€ì… ë°ì´í„°\n",
        "                    imprisonment_period = analysis.get('imprisonment_period', 'ì—†ìŒ')\n",
        "\n",
        "                    # ì›ë³¸ ë¶„ì„ ê²°ê³¼ JSON ì €ì¥\n",
        "                    raw_analysis_json = json.dumps(analysis, ensure_ascii=False)\n",
        "\n",
        "                    cursor.execute(\"\"\"\n",
        "                        INSERT OR REPLACE INTO case_analysis\n",
        "                        (conversation_id, case_type, accident_type, fault_ratio, severity_level,\n",
        "                         legal_violations, recommended_actions, party_role, settlement_amount,\n",
        "                         apology_needed, applicable_laws, fine_amount, imprisonment_period,\n",
        "                         driver_license_points, analysis_confidence, raw_analysis_json)\n",
        "                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
        "                    \"\"\", (conv[0], case_type, accident_type, fault_ratio, severity_level,\n",
        "                          legal_violations, recommended_actions, party_role, settlement_amount,\n",
        "                          apology_needed, applicable_laws, fine_amount, imprisonment_period,\n",
        "                          driver_license_points, analysis_confidence, raw_analysis_json))\n",
        "                    conn.commit()\n",
        "                    print(f\"âœ… ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ - ì‚¬ê±´ìœ í˜•: {case_type}, ê³¼ì‹¤ë¹„ìœ¨: {fault_ratio}\")\n",
        "        except Exception as e:\n",
        "            print(f\"ë¶„ì„ ì €ì¥ ì˜¤ë¥˜: {e}\")\n",
        "\n",
        "    def _safe_int(self, value, default=0):\n",
        "        \"\"\"ì•ˆì „í•œ ì •ìˆ˜ ë³€í™˜\"\"\"\n",
        "        try:\n",
        "            if isinstance(value, str):\n",
        "                numbers = re.findall(r'\\d+', value)\n",
        "                return int(numbers[0]) if numbers else default\n",
        "            return int(value) if value is not None else default\n",
        "        except:\n",
        "            return default\n",
        "\n",
        "    def _safe_float(self, value, default=0.0):\n",
        "        \"\"\"ì•ˆì „í•œ ì‹¤ìˆ˜ ë³€í™˜\"\"\"\n",
        "        try:\n",
        "            return float(value) if value is not None else default\n",
        "        except:\n",
        "            return default\n",
        "\n",
        "    def save_document(self, filename: str, original_filename: str, file_type: str,\n",
        "                      file_size: int, encoding: str, uploaded_by: int,\n",
        "                      chunk_count: int = 0, status: str = \"completed\",\n",
        "                      processing_time: float = 0.0, file_hash: str = \"\") -> int:\n",
        "        \"\"\"ë¬¸ì„œ ì •ë³´ DB ì €ì¥\"\"\"\n",
        "        try:\n",
        "            with sqlite3.connect(self.db_path) as conn:\n",
        "                cursor = conn.cursor()\n",
        "                cursor.execute(\"\"\"\n",
        "                    INSERT INTO documents\n",
        "                    (filename, original_filename, file_type, file_size, encoding, uploaded_by,\n",
        "                     chunk_count, processing_status, processed, processing_time, file_hash)\n",
        "                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
        "                \"\"\", (filename, original_filename, file_type, file_size, encoding,\n",
        "                      uploaded_by, chunk_count, status, status == \"completed\",\n",
        "                      processing_time, file_hash))\n",
        "                return cursor.lastrowid\n",
        "        except Exception as e:\n",
        "            print(f\"ë¬¸ì„œ ì •ë³´ ì €ì¥ ì˜¤ë¥˜: {e}\")\n",
        "            return 0\n",
        "\n",
        "    def get_admin_conversations(self) -> List[Dict]:\n",
        "        try:\n",
        "            with sqlite3.connect(self.db_path) as conn:\n",
        "                cursor = conn.cursor()\n",
        "                cursor.execute(\"\"\"\n",
        "                    SELECT c.session_id, u.username, u.user_type, c.title, c.started_at,\n",
        "                           c.total_messages, ca.case_type, ca.accident_type, ca.fault_ratio,\n",
        "                           ca.severity_level, ca.party_role, ca.fine_amount, ca.imprisonment_period\n",
        "                    FROM conversations c\n",
        "                    JOIN users u ON c.user_id = u.id\n",
        "                    LEFT JOIN case_analysis ca ON c.id = ca.conversation_id\n",
        "                    ORDER BY c.started_at DESC LIMIT 100\n",
        "                \"\"\")\n",
        "                return [{'session_id': row[0], 'username': row[1], 'user_type': row[2],\n",
        "                         'title': row[3], 'started_at': row[4], 'total_messages': row[5],\n",
        "                         'case_type': row[6], 'accident_type': row[7], 'fault_ratio': row[8],\n",
        "                         'severity_level': row[9], 'party_role': row[10], 'fine_amount': row[11],\n",
        "                         'imprisonment_period': row[12]} for row in cursor.fetchall()]\n",
        "        except:\n",
        "            return []\n",
        "\n",
        "    def get_documents_info(self) -> List[Dict]:\n",
        "        \"\"\"ì—…ë¡œë“œëœ ë¬¸ì„œ ì •ë³´ ì¡°íšŒ\"\"\"\n",
        "        try:\n",
        "            with sqlite3.connect(self.db_path) as conn:\n",
        "                cursor = conn.cursor()\n",
        "                cursor.execute(\"\"\"\n",
        "                    SELECT d.original_filename, d.file_type, d.file_size, d.encoding,\n",
        "                           d.chunk_count, d.processing_status, d.upload_date, u.username,\n",
        "                           d.processing_time, d.file_hash\n",
        "                    FROM documents d\n",
        "                    JOIN users u ON d.uploaded_by = u.id\n",
        "                    ORDER BY d.upload_date DESC LIMIT 100\n",
        "                \"\"\")\n",
        "                return [{'filename': row[0], 'type': row[1], 'size': row[2],\n",
        "                         'encoding': row[3], 'chunks': row[4], 'status': row[5],\n",
        "                         'uploaded_at': row[6], 'uploaded_by': row[7],\n",
        "                         'processing_time': row[8], 'file_hash': row[9]} for row in cursor.fetchall()]\n",
        "        except:\n",
        "            return []\n",
        "\n",
        "    def export_to_excel(self) -> bytes:\n",
        "        try:\n",
        "            conversations = self.get_admin_conversations()\n",
        "            documents = self.get_documents_info()\n",
        "\n",
        "            output = io.BytesIO()\n",
        "            with pd.ExcelWriter(output, engine='openpyxl') as writer:\n",
        "                pd.DataFrame(conversations).to_excel(writer, sheet_name='ëŒ€í™”ëª©ë¡', index=False)\n",
        "                pd.DataFrame(documents).to_excel(writer, sheet_name='ë¬¸ì„œëª©ë¡', index=False)\n",
        "            output.seek(0)\n",
        "            return output.getvalue()\n",
        "        except:\n",
        "            return b\"\"\n",
        "\n",
        "class OptimizedRAGSystem:\n",
        "    \"\"\"RAG ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ\"\"\"\n",
        "    def __init__(self, api_key: str, db_manager: DatabaseManager):\n",
        "        self.api_key = api_key\n",
        "        self.db = db_manager\n",
        "        self.initialized = False\n",
        "        self.upload_dir = Path(\"./uploaded_docs\")\n",
        "        self.upload_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        # ì§€ì› íŒŒì¼ í˜•ì‹\n",
        "        self.supported_extensions = {'.pdf', '.txt', '.docx', '.md'}\n",
        "        self.text_extensions = {'.txt', '.md'}\n",
        "\n",
        "        # ì²˜ë¦¬ í†µê³„\n",
        "        self.processing_stats = {\n",
        "            'total_files': 0,\n",
        "            'processed_files': 0,\n",
        "            'failed_files': 0,\n",
        "            'total_chunks': 0,\n",
        "            'processing_time': 0.0\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            self.embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
        "            os.makedirs(\"./chroma_db_redesigned\", exist_ok=True)\n",
        "\n",
        "            # í•œêµ­ì–´ íŠ¹í™” ì²­í‚¹ ì„¤ì •\n",
        "            self.text_splitters = {\n",
        "                'small': RecursiveCharacterTextSplitter(\n",
        "                    chunk_size=600, chunk_overlap=80, length_function=len,\n",
        "                    separators=[\"\\n\\n\", \"\\n\", \"ã€‚\", \".\", \"!\", \"?\", \" \", \"\"]\n",
        "                ),\n",
        "                'medium': RecursiveCharacterTextSplitter(\n",
        "                    chunk_size=1000, chunk_overlap=120, length_function=len,\n",
        "                    separators=[\"\\n\\n\", \"\\n\", \"ã€‚\", \".\", \"!\", \"?\", \" \", \"\"]\n",
        "                ),\n",
        "                'large': RecursiveCharacterTextSplitter(\n",
        "                    chunk_size=1500, chunk_overlap=200, length_function=len,\n",
        "                    separators=[\"\\n\\n\", \"\\n\", \"ã€‚\", \".\", \"!\", \"?\", \" \", \"\"]\n",
        "                )\n",
        "            }\n",
        "\n",
        "            with warnings.catch_warnings():\n",
        "                warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "                self.vectorstore = Chroma(\n",
        "                    persist_directory=\"./chroma_db_redesigned\",\n",
        "                    embedding_function=self.embeddings,\n",
        "                    collection_metadata={\n",
        "                        \"hnsw:space\": \"cosine\",\n",
        "                        \"hnsw:construction_ef\": 200,\n",
        "                        \"hnsw:M\": 16\n",
        "                    }\n",
        "                )\n",
        "\n",
        "            self.initialized = True\n",
        "            print(\"âœ… RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ RAG ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
        "            print(\"ğŸ“Œ RAG ì—†ì´ ê¸°ë³¸ ìƒë‹´ ì„œë¹„ìŠ¤ë§Œ ì œê³µë©ë‹ˆë‹¤.\")\n",
        "\n",
        "    def get_file_hash(self, file_path: str) -> str:\n",
        "        \"\"\"íŒŒì¼ í•´ì‹œ ìƒì„±\"\"\"\n",
        "        import hashlib\n",
        "        try:\n",
        "            hash_sha256 = hashlib.sha256()\n",
        "            with open(file_path, \"rb\") as f:\n",
        "                for chunk in iter(lambda: f.read(4096), b\"\"):\n",
        "                    hash_sha256.update(chunk)\n",
        "            return hash_sha256.hexdigest()[:16]\n",
        "        except:\n",
        "            return str(uuid.uuid4())[:16]\n",
        "\n",
        "    def advanced_encoding_detection(self, file_path: str) -> Tuple[str, float]:\n",
        "        \"\"\"ê³ ë„í™”ëœ ì¸ì½”ë”© ê°ì§€\"\"\"\n",
        "        try:\n",
        "            with open(file_path, 'rb') as f:\n",
        "                raw_data = f.read()\n",
        "\n",
        "            result = chardet.detect(raw_data)\n",
        "            encoding = result['encoding']\n",
        "            confidence = result['confidence']\n",
        "\n",
        "            # í•œêµ­ì–´ íŠ¹í™” ì²˜ë¦¬\n",
        "            if encoding in ['EUC-KR', 'CP949', 'euc-kr', 'cp949']:\n",
        "                return 'cp949', confidence\n",
        "            elif encoding in ['UTF-8', 'utf-8']:\n",
        "                if raw_data.startswith(b'\\xef\\xbb\\xbf'):\n",
        "                    return 'utf-8-sig', confidence\n",
        "                return 'utf-8', confidence\n",
        "            elif encoding in ['ascii', 'ASCII']:\n",
        "                return 'utf-8', confidence\n",
        "            elif confidence and confidence > 0.7:\n",
        "                return encoding.lower(), confidence\n",
        "\n",
        "            # 2ì°¨ ê²€ì‚¬: í•œêµ­ì–´ íŠ¹í™” íŒ¨í„´ ë§¤ì¹­\n",
        "            korean_patterns = [\n",
        "                b'\\xea\\xb0\\x80',  # 'ê°€' UTF-8\n",
        "                b'\\xec\\x9d\\x98',  # 'ì˜' UTF-8\n",
        "                b'\\xea\\xb3\\xa0',  # 'ê³ ' UTF-8\n",
        "                b'\\xb0\\xa1',      # 'ê°€' EUC-KR\n",
        "                b'\\xc0\\xc7',      # 'ì˜' EUC-KR\n",
        "                b'\\xb0\\xed'       # 'ê³ ' EUC-KR\n",
        "            ]\n",
        "\n",
        "            utf8_score = sum(1 for pattern in korean_patterns[:3] if pattern in raw_data)\n",
        "            euckr_score = sum(1 for pattern in korean_patterns[3:] if pattern in raw_data)\n",
        "\n",
        "            if utf8_score > euckr_score:\n",
        "                return 'utf-8', 0.8\n",
        "            elif euckr_score > 0:\n",
        "                return 'cp949', 0.8\n",
        "            else:\n",
        "                return 'utf-8', 0.5\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"ì¸ì½”ë”© ê°ì§€ ì˜¤ë¥˜: {e}\")\n",
        "            return 'utf-8', 0.5\n",
        "\n",
        "    def stream_read_text_file(self, file_path: str, encoding: str = None) -> Generator[str, None, None]:\n",
        "        \"\"\"ëŒ€ìš©ëŸ‰ í…ìŠ¤íŠ¸ íŒŒì¼ ìŠ¤íŠ¸ë¦¬ë° ì½ê¸°\"\"\"\n",
        "        if not encoding:\n",
        "            encoding, _ = self.advanced_encoding_detection(file_path)\n",
        "\n",
        "        encodings_to_try = [encoding, 'utf-8', 'cp949', 'euc-kr', 'latin-1']\n",
        "\n",
        "        for enc in encodings_to_try:\n",
        "            try:\n",
        "                with open(file_path, 'r', encoding=enc, errors='replace', buffering=8192) as f:\n",
        "                    print(f\"ğŸ“– {file_path} - ì¸ì½”ë”©: {enc}\")\n",
        "\n",
        "                    buffer = \"\"\n",
        "                    chunk_size = 4096\n",
        "\n",
        "                    while True:\n",
        "                        chunk = f.read(chunk_size)\n",
        "                        if not chunk:\n",
        "                            if buffer.strip():\n",
        "                                yield buffer\n",
        "                            break\n",
        "\n",
        "                        buffer += chunk\n",
        "\n",
        "                        while len(buffer) > 8192:\n",
        "                            split_points = [\n",
        "                                buffer.rfind('\\n\\n'),\n",
        "                                buffer.rfind('\\n'),\n",
        "                                buffer.rfind('.'),\n",
        "                                buffer.rfind('!'),\n",
        "                                buffer.rfind('?'),\n",
        "                                buffer.rfind('ã€‚')\n",
        "                            ]\n",
        "\n",
        "                            split_point = max([p for p in split_points if p > 4096])\n",
        "                            if split_point == -1:\n",
        "                                split_point = 4096\n",
        "\n",
        "                            yield buffer[:split_point]\n",
        "                            buffer = buffer[split_point:]\n",
        "\n",
        "                return\n",
        "\n",
        "            except UnicodeDecodeError:\n",
        "                continue\n",
        "            except Exception as e:\n",
        "                print(f\"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ ({enc}): {e}\")\n",
        "                continue\n",
        "\n",
        "        # ëª¨ë“  ì¸ì½”ë”© ì‹¤íŒ¨ì‹œ ë°”ì´ë„ˆë¦¬ë¡œ ì½ê¸°\n",
        "        try:\n",
        "            with open(file_path, 'rb') as f:\n",
        "                raw_data = f.read()\n",
        "                content = raw_data.decode('utf-8', errors='replace')\n",
        "                yield content\n",
        "        except:\n",
        "            yield \"íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
        "\n",
        "    def choose_optimal_splitter(self, content_length: int) -> RecursiveCharacterTextSplitter:\n",
        "        \"\"\"ë‚´ìš© ê¸¸ì´ì— ë”°ë¥¸ ìµœì  í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì„ íƒ\"\"\"\n",
        "        if content_length < 5000:\n",
        "            return self.text_splitters['small']\n",
        "        elif content_length < 20000:\n",
        "            return self.text_splitters['medium']\n",
        "        else:\n",
        "            return self.text_splitters['large']\n",
        "\n",
        "    def process_single_text_document(self, file_path: str, original_filename: str,\n",
        "                                     uploaded_by: int) -> Dict[str, Any]:\n",
        "        \"\"\"ë‹¨ì¼ í…ìŠ¤íŠ¸ ë¬¸ì„œ ì²˜ë¦¬\"\"\"\n",
        "        start_time = time.time()\n",
        "        result = {\n",
        "            'filename': original_filename,\n",
        "            'success': False,\n",
        "            'chunks': 0,\n",
        "            'encoding': 'unknown',\n",
        "            'error': None,\n",
        "            'size': 0,\n",
        "            'processing_time': 0.0,\n",
        "            'file_hash': ''\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # íŒŒì¼ ì •ë³´ ìˆ˜ì§‘\n",
        "            file_size = os.path.getsize(file_path)\n",
        "            result['size'] = file_size\n",
        "            result['file_hash'] = self.get_file_hash(file_path)\n",
        "\n",
        "            # íŒŒì¼ í¬ê¸° ì œí•œ (100MB)\n",
        "            if file_size > 100 * 1024 * 1024:\n",
        "                result['error'] = \"íŒŒì¼ í¬ê¸°ê°€ 100MBë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤\"\n",
        "                return result\n",
        "\n",
        "            file_ext = Path(file_path).suffix.lower()\n",
        "\n",
        "            # í…ìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬\n",
        "            if file_ext in self.text_extensions:\n",
        "                encoding, confidence = self.advanced_encoding_detection(file_path)\n",
        "                result['encoding'] = encoding\n",
        "\n",
        "                # ìŠ¤íŠ¸ë¦¬ë° ì½ê¸°ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í™•ë³´\n",
        "                content_chunks = list(self.stream_read_text_file(file_path, encoding))\n",
        "                full_content = \"\".join(content_chunks)\n",
        "\n",
        "                if not full_content or len(full_content.strip()) < 50:\n",
        "                    result['error'] = \"íŒŒì¼ ë‚´ìš©ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤\"\n",
        "                    return result\n",
        "\n",
        "                # ìµœì  ë¶„í• ê¸° ì„ íƒ\n",
        "                splitter = self.choose_optimal_splitter(len(full_content))\n",
        "\n",
        "                # ë¬¸ì„œ ì²­í‚¹\n",
        "                document = Document(\n",
        "                    page_content=full_content,\n",
        "                    metadata={\n",
        "                        \"source\": original_filename,\n",
        "                        \"file_type\": file_ext,\n",
        "                        \"encoding\": encoding,\n",
        "                        \"file_size\": file_size,\n",
        "                        \"upload_date\": datetime.datetime.now().isoformat(),\n",
        "                        \"uploaded_by\": uploaded_by,\n",
        "                        \"file_hash\": result['file_hash']\n",
        "                    }\n",
        "                )\n",
        "\n",
        "                chunks = splitter.split_documents([document])\n",
        "                result['chunks'] = len(chunks)\n",
        "\n",
        "                # ë°°ì¹˜ë¡œ ë²¡í„° ì €ì¥ì†Œì— ì¶”ê°€\n",
        "                batch_size = 50\n",
        "                for i in range(0, len(chunks), batch_size):\n",
        "                    batch = chunks[i:i+batch_size]\n",
        "                    self.vectorstore.add_documents(batch)\n",
        "\n",
        "            else:\n",
        "                # PDF, DOCX ë“± ë‹¤ë¥¸ í˜•ì‹ ì²˜ë¦¬\n",
        "                if file_ext == '.pdf':\n",
        "                    loader = PyPDFLoader(file_path)\n",
        "                    documents = loader.load()\n",
        "                    content = \"\\n\\n\".join([doc.page_content for doc in documents])\n",
        "                    encoding = 'binary'\n",
        "                elif file_ext == '.docx':\n",
        "                    if not DOCX_AVAILABLE:\n",
        "                        result['error'] = \"DOCX íŒŒì¼ ì§€ì› ë¶ˆê°€ (python-docx ë¯¸ì„¤ì¹˜)\"\n",
        "                        return result\n",
        "\n",
        "                    doc = DocxDocument(file_path)\n",
        "                    content_parts = []\n",
        "                    for paragraph in doc.paragraphs:\n",
        "                        if paragraph.text.strip():\n",
        "                            content_parts.append(paragraph.text.strip())\n",
        "                    content = \"\\n\\n\".join(content_parts)\n",
        "                    encoding = 'binary'\n",
        "                else:\n",
        "                    result['error'] = f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_ext}\"\n",
        "                    return result\n",
        "\n",
        "                result['encoding'] = encoding\n",
        "\n",
        "                if not content or len(content.strip()) < 50:\n",
        "                    result['error'] = \"íŒŒì¼ ë‚´ìš©ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤\"\n",
        "                    return result\n",
        "\n",
        "                # ê¸°ë³¸ ì²­í‚¹ ì²˜ë¦¬\n",
        "                splitter = self.choose_optimal_splitter(len(content))\n",
        "                document = Document(\n",
        "                    page_content=content,\n",
        "                    metadata={\n",
        "                        \"source\": original_filename,\n",
        "                        \"file_type\": file_ext,\n",
        "                        \"encoding\": encoding,\n",
        "                        \"file_size\": file_size,\n",
        "                        \"upload_date\": datetime.datetime.now().isoformat(),\n",
        "                        \"uploaded_by\": uploaded_by,\n",
        "                        \"file_hash\": result['file_hash']\n",
        "                    }\n",
        "                )\n",
        "\n",
        "                chunks = splitter.split_documents([document])\n",
        "                result['chunks'] = len(chunks)\n",
        "\n",
        "                # ë²¡í„° ì €ì¥ì†Œì— ì¶”ê°€\n",
        "                self.vectorstore.add_documents(chunks)\n",
        "\n",
        "            # ì²˜ë¦¬ ì™„ë£Œ\n",
        "            processing_time = time.time() - start_time\n",
        "            result['processing_time'] = processing_time\n",
        "            result['success'] = True\n",
        "\n",
        "            # DBì— ê¸°ë¡\n",
        "            self.db.save_document(\n",
        "                filename=original_filename,\n",
        "                original_filename=original_filename,\n",
        "                file_type=file_ext,\n",
        "                file_size=file_size,\n",
        "                encoding=result['encoding'],\n",
        "                uploaded_by=uploaded_by,\n",
        "                chunk_count=result['chunks'],\n",
        "                status=\"completed\",\n",
        "                processing_time=processing_time,\n",
        "                file_hash=result['file_hash']\n",
        "            )\n",
        "\n",
        "            print(f\"âœ… {original_filename}: {result['chunks']}ê°œ ì²­í¬, {processing_time:.2f}ì´ˆ\")\n",
        "\n",
        "        except Exception as e:\n",
        "            result['error'] = f\"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}\"\n",
        "            result['processing_time'] = time.time() - start_time\n",
        "            print(f\"âŒ {original_filename}: {result['error']}\")\n",
        "\n",
        "        return result\n",
        "\n",
        "    def process_documents_parallel(self, files: List[Any], uploaded_by: int,\n",
        "                                   max_workers: int = 4) -> Dict[str, Any]:\n",
        "        \"\"\"ë³‘ë ¬ ë¬¸ì„œ ì²˜ë¦¬ (ê°œì„ ë¨)\"\"\"\n",
        "        if not self.initialized:\n",
        "            return {\"success\": False, \"error\": \"RAG ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤\", \"results\": []}\n",
        "\n",
        "        if not files:\n",
        "            return {\"success\": False, \"error\": \"ì—…ë¡œë“œí•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤\", \"results\": []}\n",
        "\n",
        "        start_time = time.time()\n",
        "        results = {\n",
        "            \"success\": True,\n",
        "            \"total_files\": len(files),\n",
        "            \"processed\": 0,\n",
        "            \"failed\": 0,\n",
        "            \"results\": [],\n",
        "            \"errors\": [],\n",
        "            \"total_chunks\": 0,\n",
        "            \"total_processing_time\": 0.0\n",
        "        }\n",
        "\n",
        "        print(f\"ğŸš€ {len(files)}ê°œ íŒŒì¼ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘... (ì›Œì»¤: {max_workers}ê°œ)\")\n",
        "\n",
        "        # ì„ì‹œ íŒŒì¼ ì¤€ë¹„\n",
        "        temp_files = []\n",
        "        for i, file in enumerate(files):\n",
        "            try:\n",
        "                original_filename = os.path.basename(file.name)\n",
        "                file_ext = Path(original_filename).suffix.lower()\n",
        "\n",
        "                # ì§€ì› í˜•ì‹ í™•ì¸\n",
        "                if file_ext not in self.supported_extensions:\n",
        "                    error_msg = f\"{original_filename}: ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ ({file_ext})\"\n",
        "                    results[\"errors\"].append(error_msg)\n",
        "                    results[\"failed\"] += 1\n",
        "                    results[\"results\"].append({\n",
        "                        \"filename\": original_filename,\n",
        "                        \"success\": False,\n",
        "                        \"error\": error_msg\n",
        "                    })\n",
        "                    continue\n",
        "\n",
        "                # ì„ì‹œ íŒŒì¼ ë³µì‚¬\n",
        "                temp_path = self.upload_dir / f\"temp_{uuid.uuid4()}_{original_filename}\"\n",
        "                shutil.copy2(file.name, temp_path)\n",
        "                temp_files.append((str(temp_path), original_filename, i))\n",
        "\n",
        "            except Exception as e:\n",
        "                error_msg = f\"íŒŒì¼ ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜: {str(e)}\"\n",
        "                results[\"errors\"].append(error_msg)\n",
        "                results[\"failed\"] += 1\n",
        "                results[\"results\"].append({\n",
        "                    \"filename\": getattr(file, 'name', 'unknown'),\n",
        "                    \"success\": False,\n",
        "                    \"error\": error_msg\n",
        "                })\n",
        "\n",
        "        # ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰\n",
        "        def process_single_with_info(args):\n",
        "            temp_path, original_filename, file_index = args\n",
        "            return self.process_single_text_document(temp_path, original_filename, uploaded_by)\n",
        "\n",
        "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "            future_to_file = {executor.submit(process_single_with_info, file_info): file_info\n",
        "                              for file_info in temp_files}\n",
        "\n",
        "            for future in as_completed(future_to_file):\n",
        "                file_info = future_to_file[future]\n",
        "                temp_path, original_filename, file_index = file_info\n",
        "\n",
        "                try:\n",
        "                    result = future.result()\n",
        "                    results[\"results\"].append(result)\n",
        "\n",
        "                    if result[\"success\"]:\n",
        "                        results[\"processed\"] += 1\n",
        "                        results[\"total_chunks\"] += result.get(\"chunks\", 0)\n",
        "                        print(f\"âœ… [{file_index+1}/{len(files)}] {original_filename} - {result.get('chunks', 0)}ê°œ ì²­í¬\")\n",
        "                    else:\n",
        "                        results[\"failed\"] += 1\n",
        "                        results[\"errors\"].append(f\"{original_filename}: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}\")\n",
        "                        print(f\"âŒ [{file_index+1}/{len(files)}] {original_filename}: {result.get('error')}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    error_msg = f\"ë³‘ë ¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}\"\n",
        "                    results[\"errors\"].append(error_msg)\n",
        "                    results[\"failed\"] += 1\n",
        "                    results[\"results\"].append({\n",
        "                        \"filename\": original_filename,\n",
        "                        \"success\": False,\n",
        "                        \"error\": error_msg\n",
        "                    })\n",
        "                    print(f\"âŒ [{file_index+1}/{len(files)}] {original_filename} ì²˜ë¦¬ ì˜¤ë¥˜: {e}\")\n",
        "\n",
        "                finally:\n",
        "                    # ì„ì‹œ íŒŒì¼ ì •ë¦¬\n",
        "                    try:\n",
        "                        Path(temp_path).unlink()\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "        # ë²¡í„° ì €ì¥ì†Œ ìµœì¢… ì €ì¥\n",
        "        try:\n",
        "            if results[\"processed\"] > 0:\n",
        "                self.vectorstore.persist()\n",
        "                print(\"ğŸ’¾ ë²¡í„° ì €ì¥ì†Œ ì €ì¥ ì™„ë£Œ\")\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ ë²¡í„° ì €ì¥ì†Œ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "        # ì²˜ë¦¬ í†µê³„ ì—…ë°ì´íŠ¸\n",
        "        total_processing_time = time.time() - start_time\n",
        "        results[\"total_processing_time\"] = total_processing_time\n",
        "\n",
        "        self.processing_stats.update({\n",
        "            'total_files': self.processing_stats['total_files'] + results['total_files'],\n",
        "            'processed_files': self.processing_stats['processed_files'] + results['processed'],\n",
        "            'failed_files': self.processing_stats['failed_files'] + results['failed'],\n",
        "            'total_chunks': self.processing_stats['total_chunks'] + results['total_chunks'],\n",
        "            'processing_time': self.processing_stats['processing_time'] + total_processing_time\n",
        "        })\n",
        "\n",
        "        if results[\"processed\"] > 0:\n",
        "            results[\"success\"] = True\n",
        "\n",
        "        print(f\"ğŸ¯ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ: {results['processed']}ê°œ ì„±ê³µ, {results['failed']}ê°œ ì‹¤íŒ¨\")\n",
        "        print(f\"â±ï¸ ì´ ì²˜ë¦¬ ì‹œê°„: {total_processing_time:.2f}ì´ˆ\")\n",
        "        print(f\"ğŸ“Š ì´ ì²­í¬ ìˆ˜: {results['total_chunks']:,}ê°œ\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def search(self, query: str, k: int = 5) -> str:\n",
        "        \"\"\"í–¥ìƒëœ ê²€ìƒ‰ ê¸°ëŠ¥\"\"\"\n",
        "        if not self.initialized:\n",
        "            print(\"âš ï¸ RAG ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "            return \"\"\n",
        "\n",
        "        try:\n",
        "            processed_query = query.strip()\n",
        "            if not processed_query:\n",
        "                print(\"âš ï¸ ê²€ìƒ‰ ì¿¼ë¦¬ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.\")\n",
        "                return \"\"\n",
        "\n",
        "            print(f\"ğŸ” RAG ê²€ìƒ‰ ì‹œì‘: '{processed_query[:50]}...'\")\n",
        "\n",
        "            docs = self.vectorstore.similarity_search(processed_query, k=k*2)\n",
        "\n",
        "            if not docs:\n",
        "                print(\"ğŸ“„ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "                return \"\"\n",
        "\n",
        "            print(f\"ğŸ“„ {len(docs)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ\")\n",
        "\n",
        "            results = []\n",
        "            seen_content = set()\n",
        "\n",
        "            for i, doc in enumerate(docs, 1):\n",
        "                content = doc.page_content.strip()\n",
        "\n",
        "                # ì¤‘ë³µ ì œê±°\n",
        "                content_signature = hash(content[:300])\n",
        "                if content_signature in seen_content:\n",
        "                    continue\n",
        "                seen_content.add(content_signature)\n",
        "\n",
        "                # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ\n",
        "                metadata = doc.metadata\n",
        "                source = metadata.get('source', 'Unknown')\n",
        "                file_type = metadata.get('file_type', '')\n",
        "                file_size = metadata.get('file_size', 0)\n",
        "\n",
        "                # ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°\n",
        "                relevance_score = self._calculate_relevance(processed_query, content)\n",
        "\n",
        "                # ë‚®ì€ ê´€ë ¨ì„± í•„í„°ë§\n",
        "                if relevance_score < 0.1:\n",
        "                    continue\n",
        "\n",
        "                # ë‚´ìš© ê¸¸ì´ ë™ì  ì¡°ì •\n",
        "                max_length = 1000 if len(results) < 3 else 600\n",
        "                if len(content) > max_length:\n",
        "                    content = content[:max_length] + \"...\"\n",
        "\n",
        "                result_text = f\"\"\"[ì°¸ê³ ë¬¸ì„œ {len(results)+1}] ğŸ“„ {source} ({file_type}, {file_size:,} bytes)\n",
        "ê´€ë ¨ë„: {relevance_score:.2f}\n",
        "{content}\n",
        "{'='*50}\"\"\"\n",
        "                results.append(result_text)\n",
        "\n",
        "                # ìµœëŒ€ ê²°ê³¼ ì œí•œ\n",
        "                if len(results) >= k:\n",
        "                    break\n",
        "\n",
        "            final_result = \"\\n\\n\".join(results)\n",
        "            print(f\"âœ… RAG ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼\")\n",
        "            return final_result\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"RAG ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\"\n",
        "            print(f\"âŒ {error_msg}\")\n",
        "            return \"\"\n",
        "\n",
        "    def _calculate_relevance(self, query: str, content: str) -> float:\n",
        "        \"\"\"ê°„ë‹¨í•œ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°\"\"\"\n",
        "        try:\n",
        "            query_words = set(query.lower().split())\n",
        "            content_words = set(content.lower().split())\n",
        "\n",
        "            if not query_words:\n",
        "                return 0.0\n",
        "\n",
        "            intersection = query_words.intersection(content_words)\n",
        "            return len(intersection) / len(query_words)\n",
        "        except:\n",
        "            return 0.0\n",
        "\n",
        "    def get_collection_info(self) -> Dict[str, Any]:\n",
        "        \"\"\"ì»¬ë ‰ì…˜ ì •ë³´ ì¡°íšŒ\"\"\"\n",
        "        if not self.initialized:\n",
        "            return {\"error\": \"RAG ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤\"}\n",
        "\n",
        "        try:\n",
        "            collection = self.vectorstore._collection\n",
        "            count = collection.count()\n",
        "\n",
        "            return {\n",
        "                \"document_count\": count,\n",
        "                \"collection_name\": collection.name,\n",
        "                \"status\": \"í™œì„±\" if count > 0 else \"ë¹„ì–´ìˆìŒ\",\n",
        "                \"processing_stats\": self.processing_stats.copy(),\n",
        "                \"system_info\": {\n",
        "                    \"supported_extensions\": list(self.supported_extensions),\n",
        "                    \"text_extensions\": list(self.text_extensions),\n",
        "                    \"chunk_strategies\": list(self.text_splitters.keys())\n",
        "                }\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\"error\": f\"ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}\"}\n",
        "\n",
        "    def optimize_storage(self):\n",
        "        \"\"\"ë²¡í„° ì €ì¥ì†Œ ìµœì í™”\"\"\"\n",
        "        try:\n",
        "            if self.initialized:\n",
        "                self.vectorstore.persist()\n",
        "                print(\"ğŸ’¾ ë²¡í„° ì €ì¥ì†Œ ìµœì í™” ì™„ë£Œ\")\n",
        "                return True\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ ì €ì¥ì†Œ ìµœì í™” ì‹¤íŒ¨: {e}\")\n",
        "            return False\n",
        "\n",
        "class ConversationAnalyzer:\n",
        "    \"\"\"ëŒ€í™” ë¶„ì„ ë° ìš”ì•½ ì—”ì§„\"\"\"\n",
        "    def __init__(self, client: openai.OpenAI):\n",
        "        self.client = client\n",
        "\n",
        "    def analyze_conversation(self, messages: List[Dict]) -> Dict:\n",
        "        \"\"\"ëŒ€í™” ë¶„ì„\"\"\"\n",
        "        try:\n",
        "            conversation_text = \"\\n\".join([f\"{msg['role']}: {msg['content']}\"\n",
        "                                         for msg in messages if msg['role'] in ['user', 'assistant']])\n",
        "\n",
        "            if not conversation_text.strip():\n",
        "                return self._get_default_analysis()\n",
        "\n",
        "            # ê°œì„ ëœ í”„ë¡¬í”„íŠ¸\n",
        "            prompt = f\"\"\"ë‹¤ìŒì€ êµí†µë²• ìƒë‹´ ëŒ€í™”ì…ë‹ˆë‹¤. ì´ë¥¼ ë¶„ì„í•˜ì—¬ ì •í™•í•œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.\n",
        "\n",
        "ëŒ€í™” ë‚´ìš©:\n",
        "{conversation_text}\n",
        "\n",
        "ë‹¤ìŒ ê¸°ì¤€ì— ë”°ë¼ ë¶„ì„í•˜ì„¸ìš”:\n",
        "\n",
        "1. case_type:\n",
        "   - \"criminal\": í˜•ì‚¬ì‚¬ê±´ (ìŒì£¼ìš´ì „, ë¬´ë©´í—ˆ, ëº‘ì†Œë‹ˆ ë“±)\n",
        "   - \"civil\": ë¯¼ì‚¬ë¶„ìŸ (ì†í•´ë°°ìƒ, ê³¼ì‹¤ë¹„ìœ¨ ë‹¤íˆ¼)\n",
        "   - \"consultation\": ì¼ë°˜ìƒë‹´ (ë²•ë¥ ë¬¸ì˜, ì ˆì°¨ì•ˆë‚´)\n",
        "   - \"mixed\": í˜•ì‚¬+ë¯¼ì‚¬ ë³µí•©\n",
        "\n",
        "2. accident_type: ì‚¬ê³  ìœ í˜•ì„ êµ¬ì²´ì ìœ¼ë¡œ (ì˜ˆ: \"êµì°¨ë¡œ ì§ì§„ì°¨ëŸ‰ vs ì¢ŒíšŒì „ì°¨ëŸ‰ ì¶©ëŒ\")\n",
        "\n",
        "3. fault_ratio: ê³¼ì‹¤ë¹„ìœ¨ (ì˜ˆ: \"70:30\", \"100:0\", \"50:50\", \"ë¯¸ì •\")\n",
        "\n",
        "4. severity_level:\n",
        "   - \"minor\": ê²½ë¯¸í•œ ì ‘ì´‰ì‚¬ê³ , ë¬¼í”¼ì‚¬ê³ \n",
        "   - \"moderate\": ë¶€ìƒì ë°œìƒ, ì¤‘ê°„ ì •ë„ í”¼í•´\n",
        "   - \"severe\": ì¤‘ìƒì/ì‚¬ë§ì ë°œìƒ, ì‹¬ê°í•œ ì‚¬ê³ \n",
        "\n",
        "5. legal_violations: ìœ„ë°˜í•œ êµí†µë²•ê·œ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: [\"ì‹ í˜¸ìœ„ë°˜\", \"ì•ˆì „ê±°ë¦¬ ë¯¸í™•ë³´\"])\n",
        "\n",
        "6. recommended_actions: ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­ ë¦¬ìŠ¤íŠ¸\n",
        "\n",
        "7. party_role: ìƒë‹´ì ì—­í• \n",
        "   - \"perpetrator\": ê°€í•´ì/ìœ„ë°˜ì\n",
        "   - \"victim\": í”¼í•´ì\n",
        "   - \"witness\": ëª©ê²©ì\n",
        "   - \"neutral\": ì¤‘ë¦½ì  ë¬¸ì˜\n",
        "\n",
        "8. settlement_amount: ì˜ˆìƒ í•©ì˜ê¸ˆ (ìˆ«ìë§Œ, 0ì´ë©´ í•´ë‹¹ì—†ìŒ)\n",
        "\n",
        "9. apology_needed: ë°˜ì„±ë¬¸ í•„ìš” ì—¬ë¶€ (true/false)\n",
        "\n",
        "10. applicable_laws: ì ìš© ë²•ë¥  ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: [\"ë„ë¡œêµí†µë²• ì œ13ì¡°\", \"í˜•ë²• ì œ268ì¡°\"])\n",
        "\n",
        "11. fine_amount: ì˜ˆìƒ ë²Œê¸ˆì•¡ (ìˆ«ìë§Œ, 0ì´ë©´ í•´ë‹¹ì—†ìŒ)\n",
        "\n",
        "12. imprisonment_period: ì˜ˆìƒ ì§•ì—­ê¸°ê°„ (\"ì—†ìŒ\", \"ë²Œê¸ˆí˜•\", \"6ì›” ì´í•˜\" ë“±)\n",
        "\n",
        "13. driver_license_points: ìš´ì „ë©´í—ˆ ë²Œì  (ìˆ«ì)\n",
        "\n",
        "14. confidence: ë¶„ì„ ì‹ ë¢°ë„ (0.0~1.0)\n",
        "\n",
        "ë°˜ë“œì‹œ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ì¶”ê°€ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”.\"\"\"\n",
        "\n",
        "            print(\"ğŸ” GPT-4oë¡œ ëŒ€í™” ë¶„ì„ ì¤‘...\")\n",
        "\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=\"gpt-4o\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ êµí†µì‚¬ê³  ë²•ë¥  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ëŒ€í™”ë¥¼ ë¶„ì„í•˜ì—¬ ì •í™•í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=0.1,\n",
        "                max_tokens=1500\n",
        "            )\n",
        "\n",
        "            response_text = response.choices[0].message.content.strip()\n",
        "            print(f\"ğŸ“„ GPT ì‘ë‹µ ê¸¸ì´: {len(response_text)} ë¬¸ì\")\n",
        "\n",
        "            # JSON íŒŒì‹± ì‹œë„\n",
        "            analysis = self._parse_gpt_response(response_text)\n",
        "\n",
        "            if analysis:\n",
        "                print(\"âœ… ëŒ€í™” ë¶„ì„ ì™„ë£Œ\")\n",
        "                return analysis\n",
        "            else:\n",
        "                print(\"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©\")\n",
        "                return self._get_default_analysis()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ëŒ€í™” ë¶„ì„ ì˜¤ë¥˜: {e}\")\n",
        "            return self._get_default_analysis()\n",
        "\n",
        "    def _parse_gpt_response(self, response_text: str) -> Optional[Dict]:\n",
        "        \"\"\"GPT ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ ë° íŒŒì‹±\"\"\"\n",
        "        try:\n",
        "            # JSON ë¸”ë¡ ì°¾ê¸°\n",
        "            json_start = response_text.find('{')\n",
        "            json_end = response_text.rfind('}') + 1\n",
        "\n",
        "            if json_start == -1 or json_end == 0:\n",
        "                json_text = response_text\n",
        "            else:\n",
        "                json_text = response_text[json_start:json_end]\n",
        "\n",
        "            # JSON íŒŒì‹±\n",
        "            analysis = json.loads(json_text)\n",
        "\n",
        "            # ë°ì´í„° ìœ íš¨ì„± ê²€ì¦\n",
        "            analysis = self._validate_analysis(analysis)\n",
        "\n",
        "            return analysis\n",
        "\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"JSON íŒŒì‹± ì˜¤ë¥˜: {e}\")\n",
        "            try:\n",
        "                import re\n",
        "                json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
        "                if json_match:\n",
        "                    json_text = json_match.group()\n",
        "                    analysis = json.loads(json_text)\n",
        "                    return self._validate_analysis(analysis)\n",
        "            except:\n",
        "                pass\n",
        "            return None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {e}\")\n",
        "            return None\n",
        "\n",
        "    def _validate_analysis(self, analysis: Dict) -> Dict:\n",
        "        \"\"\"ë¶„ì„ ê²°ê³¼ ìœ íš¨ì„± ê²€ì¦ ë° ê¸°ë³¸ê°’ ì„¤ì •\"\"\"\n",
        "        # í•„ìˆ˜ í•„ë“œ ê¸°ë³¸ê°’ ì„¤ì •\n",
        "        defaults = {\n",
        "            'case_type': 'consultation',\n",
        "            'accident_type': 'ê¸°íƒ€',\n",
        "            'fault_ratio': 'ë¯¸ì •',\n",
        "            'severity_level': 'minor',\n",
        "            'legal_violations': [],\n",
        "            'recommended_actions': [],\n",
        "            'party_role': 'neutral',\n",
        "            'settlement_amount': 0,\n",
        "            'apology_needed': False,\n",
        "            'applicable_laws': [],\n",
        "            'fine_amount': 0,\n",
        "            'imprisonment_period': 'ì—†ìŒ',\n",
        "            'driver_license_points': 0,\n",
        "            'confidence': 0.7\n",
        "        }\n",
        "\n",
        "        # ê¸°ë³¸ê°’ìœ¼ë¡œ ëˆ„ë½ëœ í•„ë“œ ì±„ìš°ê¸°\n",
        "        for key, default_value in defaults.items():\n",
        "            if key not in analysis:\n",
        "                analysis[key] = default_value\n",
        "\n",
        "        # ë°ì´í„° íƒ€ì… ê²€ì¦\n",
        "        analysis['settlement_amount'] = self._safe_int(analysis.get('settlement_amount', 0))\n",
        "        analysis['fine_amount'] = self._safe_int(analysis.get('fine_amount', 0))\n",
        "        analysis['driver_license_points'] = self._safe_int(analysis.get('driver_license_points', 0))\n",
        "        analysis['confidence'] = self._safe_float(analysis.get('confidence', 0.7))\n",
        "        analysis['apology_needed'] = bool(analysis.get('apology_needed', False))\n",
        "\n",
        "        # ë¦¬ìŠ¤íŠ¸ íƒ€ì… ê²€ì¦\n",
        "        for list_field in ['legal_violations', 'recommended_actions', 'applicable_laws']:\n",
        "            if not isinstance(analysis.get(list_field), list):\n",
        "                analysis[list_field] = []\n",
        "\n",
        "        return analysis\n",
        "\n",
        "    def _safe_int(self, value, default=0):\n",
        "        \"\"\"ì•ˆì „í•œ ì •ìˆ˜ ë³€í™˜\"\"\"\n",
        "        try:\n",
        "            if isinstance(value, str):\n",
        "                numbers = re.findall(r'\\d+', value)\n",
        "                return int(numbers[0]) if numbers else default\n",
        "            return int(value) if value is not None else default\n",
        "        except:\n",
        "            return default\n",
        "\n",
        "    def _safe_float(self, value, default=0.0):\n",
        "        \"\"\"ì•ˆì „í•œ ì‹¤ìˆ˜ ë³€í™˜\"\"\"\n",
        "        try:\n",
        "            return float(value) if value is not None else default\n",
        "        except:\n",
        "            return default\n",
        "\n",
        "    def _get_default_analysis(self) -> Dict:\n",
        "        \"\"\"ê¸°ë³¸ ë¶„ì„ ê²°ê³¼\"\"\"\n",
        "        return {\n",
        "            \"case_type\": \"consultation\",\n",
        "            \"accident_type\": \"ê¸°íƒ€\",\n",
        "            \"fault_ratio\": \"ë¯¸ì •\",\n",
        "            \"severity_level\": \"minor\",\n",
        "            \"legal_violations\": [],\n",
        "            \"recommended_actions\": [\"ì „ë¬¸ê°€ ìƒë‹´ ê¶Œì¥\"],\n",
        "            \"party_role\": \"neutral\",\n",
        "            \"settlement_amount\": 0,\n",
        "            \"apology_needed\": False,\n",
        "            \"applicable_laws\": [],\n",
        "            \"fine_amount\": 0,\n",
        "            \"imprisonment_period\": \"ì—†ìŒ\",\n",
        "            \"driver_license_points\": 0,\n",
        "            \"confidence\": 0.3\n",
        "        }\n",
        "\n",
        "    def generate_summary(self, messages: List[Dict], analysis: Dict) -> str:\n",
        "        \"\"\"ëŒ€í™” ìš”ì•½ ìƒì„±\"\"\"\n",
        "        try:\n",
        "            conversation_text = \"\\n\".join([f\"{msg['role']}: {msg['content']}\"\n",
        "                                         for msg in messages if msg['role'] in ['user', 'assistant']])\n",
        "\n",
        "            prompt = f\"\"\"ë‹¤ìŒ êµí†µë²• ìƒë‹´ì„ ìš”ì•½í•´ì£¼ì„¸ìš”:\n",
        "\n",
        "{conversation_text}\n",
        "\n",
        "ë¶„ì„ ê²°ê³¼: {json.dumps(analysis, ensure_ascii=False)}\n",
        "\n",
        "ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”:\n",
        "\n",
        "## ğŸš¨ ìƒí™© ìš”ì•½\n",
        "- ì‚¬ê³ ìœ í˜•: {analysis.get('accident_type', 'ê¸°íƒ€')}\n",
        "- ê³¼ì‹¤ë¹„ìœ¨: {analysis.get('fault_ratio', 'ë¯¸ì •')}\n",
        "- ìƒë‹´ì ì—­í• : {analysis.get('party_role', 'ì¤‘ë¦½')}\n",
        "\n",
        "## âš¡ ì§€ê¸ˆ ë‹¹ì¥ í•´ì•¼í•  ê²ƒ\n",
        "1. ì¦‰ì‹œ ì¡°ì¹˜ì‚¬í•­\n",
        "2. ì¦ê±° ìˆ˜ì§‘\n",
        "3. ê´€ë ¨ ê¸°ê´€ ì‹ ê³ \n",
        "\n",
        "## âš–ï¸ ì²˜ë²Œ ë° ê³¼ì‹¤ë¹„ìœ¨\n",
        "- **ê³¼ì‹¤ë¹„ìœ¨**: {analysis.get('fault_ratio', 'ë¯¸ì •')}\n",
        "- **ì˜ˆìƒ ì²˜ë²Œ**: ë²Œê¸ˆ {analysis.get('fine_amount', 0):,}ì›, {analysis.get('imprisonment_period', 'ì—†ìŒ')}\n",
        "- **ë²•ì  ê·¼ê±°**: {', '.join(analysis.get('applicable_laws', ['í•´ë‹¹ì—†ìŒ']))}\n",
        "- **ë²Œì **: {analysis.get('driver_license_points', 0)}ì \n",
        "\n",
        "## ğŸ“ í›„ì† ì¡°ì¹˜\n",
        "- **ë°˜ì„±ë¬¸**: {'í•„ìš”' if analysis.get('apology_needed') else 'ë¶ˆí•„ìš”'}\n",
        "- **í•©ì˜ ê´€ë ¨**: ì˜ˆìƒ í•©ì˜ê¸ˆ {analysis.get('settlement_amount', 0):,}ì›\n",
        "- **ê¸°íƒ€ ê¶Œì¥ì‚¬í•­**: {', '.join(analysis.get('recommended_actions', ['ì „ë¬¸ê°€ ìƒë‹´']))}\n",
        "\n",
        "## ğŸ“‹ ìœ„ë°˜ ë²•ê·œ\n",
        "{chr(10).join([f\"- {violation}\" for violation in analysis.get('legal_violations', ['í•´ë‹¹ì—†ìŒ'])])}\n",
        "\n",
        "ë²ˆí˜¸ì™€ ë¶ˆë¦¿ í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•´ì„œ ê¹”ë”í•˜ê²Œ ì •ë¦¬í•˜ì„¸ìš”.\"\"\"\n",
        "\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=\"gpt-4o\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"ë²•ë¥  ìƒë‹´ ìš”ì•½ ì „ë¬¸ê°€\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=0.2\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {e}\")\n",
        "            return \"ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\"\n",
        "\n",
        "class ChatMoonCheolSystem:\n",
        "    \"\"\"ì±—ë¬¸ì²  ë©”ì¸ ì‹œìŠ¤í…œ\"\"\"\n",
        "    def __init__(self):\n",
        "        self.api_key = self._get_api_key()\n",
        "        self.client = openai.OpenAI(api_key=self.api_key)\n",
        "        self.db = DatabaseManager()\n",
        "        self.rag = OptimizedRAGSystem(self.api_key, self.db)\n",
        "        self.analyzer = ConversationAnalyzer(self.client)\n",
        "\n",
        "        self.current_user = None\n",
        "        self.current_session_id = None\n",
        "\n",
        "        self.persona = \"\"\"ë‹¹ì‹ ì€ ì±—ë¬¸ì² ì…ë‹ˆë‹¤. êµí†µì‚¬ê³  ì „ë¬¸ ë³€í˜¸ì‚¬ë¡œì„œ:\n",
        "\n",
        "ğŸ¯ íŠ¹ì§•:\n",
        "- ì •ì¤‘í•˜ê³  ì „ë¬¸ì ì´ë©´ì„œë„ ì¹œê·¼í•œ ì–´ì¡°\n",
        "- \"~ì…ë‹ˆë‹¤\", \"~ë„¤ìš”\" ë“± ì¡´ëŒ“ë§ ì‚¬ìš©\n",
        "- ë²•ë¥  ìš©ì–´ë¥¼ ì‰½ê²Œ ì„¤ëª…\n",
        "- í™•ì‹¤í•œ ê·¼ê±° ì œì‹œ í›„ ëª…í™•í•œ íŒë‹¨\n",
        "- ì‹¤ë¬´ ê²½í—˜ ê¸°ë°˜ í˜„ì‹¤ì  ì¡°ì–¸\n",
        "\n",
        "ğŸ“š ì „ë¬¸ ë¶„ì•¼:\n",
        "- ë„ë¡œêµí†µë²• ë° ê´€ë ¨ ë²•ë ¹\n",
        "- êµí†µì‚¬ê³  ê³¼ì‹¤ë¹„ìœ¨ íŒì •\n",
        "- ìŒì£¼ìš´ì „, ê³¼ì† ë“± êµí†µë²•ê·œ ìœ„ë°˜\n",
        "- êµí†µì‚¬ê³  ì²˜ë¦¬ ì ˆì°¨\n",
        "\n",
        "í•­ìƒ ë²•ì  ê·¼ê±°ë¥¼ ëª…ì‹œí•˜ê³ , ê³¼ì‹¤ë¹„ìœ¨ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”.\n",
        "ìƒí™©ì— ë”°ë¼ ì¶”ê°€ ì„œë¹„ìŠ¤ë¥¼ ì ê·¹ ì œì•ˆí•˜ì„¸ìš”.\"\"\"\n",
        "\n",
        "    def _get_api_key(self) -> str:\n",
        "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "        if not api_key:\n",
        "            api_key = input(\"ğŸ”‘ OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”: \").strip()\n",
        "            if not api_key:\n",
        "                sys.exit(\"âŒ API í‚¤ í•„ìš”\")\n",
        "        return api_key\n",
        "\n",
        "    def login(self, username: str, password: str) -> Tuple[bool, str, Optional[Dict]]:\n",
        "        if not username or not password:\n",
        "            return False, \"ì‚¬ìš©ìëª…ê³¼ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\", None\n",
        "        user = self.db.authenticate(username, password)\n",
        "        if user:\n",
        "            self.current_user = user\n",
        "            return True, f\"{user['username']}ë‹˜({user['user_type']}) í™˜ì˜í•©ë‹ˆë‹¤!\", user\n",
        "        return False, \"ë¡œê·¸ì¸ ì‹¤íŒ¨: ì‚¬ìš©ìëª… ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.\", None\n",
        "\n",
        "    def register(self, username: str, password: str, user_type: str, email: str = \"\") -> Tuple[bool, str]:\n",
        "        if not username or not password:\n",
        "            return False, \"ì‚¬ìš©ìëª…ê³¼ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\"\n",
        "        if self.db.create_user(username, password, user_type, email):\n",
        "            return True, \"íšŒì›ê°€ì…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\"\n",
        "        return False, \"íšŒì›ê°€ì… ì‹¤íŒ¨: ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì‚¬ìš©ìëª…ì…ë‹ˆë‹¤.\"\n",
        "\n",
        "    def start_conversation(self, title: str = \"ìƒˆ ìƒë‹´\") -> str:\n",
        "        if not self.current_user:\n",
        "            return None\n",
        "        session_id = self.db.create_conversation(self.current_user['id'], title)\n",
        "        self.current_session_id = session_id\n",
        "        return session_id\n",
        "\n",
        "    def analyze_image(self, image_file) -> str:\n",
        "        if not image_file:\n",
        "            return \"\"\n",
        "        try:\n",
        "            if hasattr(image_file, 'read'):\n",
        "                image_data = image_file.read()\n",
        "            else:\n",
        "                with open(image_file, 'rb') as f:\n",
        "                    image_data = f.read()\n",
        "\n",
        "            image_base64 = base64.b64encode(image_data).decode('utf-8')\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=\"gpt-4o\", messages=[{\n",
        "                    \"role\": \"user\", \"content\": [{\n",
        "                        \"type\": \"text\", \"text\": \"\"\"êµí†µì‚¬ê³  ì´ë¯¸ì§€ ë¶„ì„:\n",
        "1. ì°¨ì¢… ë° ì°¨ëŸ‰ ìƒíƒœ\n",
        "2. ì‚¬ê³  ìœ í˜•\n",
        "3. ë„ë¡œ í™˜ê²½\n",
        "4. ì‹ í˜¸ë“±/í‘œì§€íŒ\n",
        "5. ë‚ ì”¨/ì‹œì•¼\n",
        "6. ì†ìƒ ë¶€ìœ„\n",
        "7. êµí†µ ìƒí™©\n",
        "8. ê³¼ì‹¤ íŒë‹¨ ìš”ì†Œ\"\"\"\n",
        "                    }, {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_base64}\"}\n",
        "                    }]\n",
        "                }], max_tokens=500\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            print(f\"ì´ë¯¸ì§€ ë¶„ì„ ì˜¤ë¥˜: {e}\")\n",
        "            return \"ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ\"\n",
        "\n",
        "    def generate_response(self, user_input: str, chat_history: List, image_analysis: str = \"\") -> str:\n",
        "        \"\"\"ì‘ë‹µ ìƒì„±\"\"\"\n",
        "        try:\n",
        "            # RAG ê²€ìƒ‰ ìµœì í™”\n",
        "            legal_context = \"\"\n",
        "            if self.rag.initialized:\n",
        "                print(\"ğŸ” RAG ê²€ìƒ‰ ì‹œì‘...\")\n",
        "                legal_context = self.rag.search(user_input, k=8)\n",
        "                if legal_context:\n",
        "                    print(f\"âœ… RAG ê²€ìƒ‰ ì™„ë£Œ: {len(legal_context)} ë¬¸ì\")\n",
        "                else:\n",
        "                    print(\"âš ï¸ RAG ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ\")\n",
        "            else:\n",
        "                print(\"âš ï¸ RAG ì‹œìŠ¤í…œ ë¹„í™œì„±í™”\")\n",
        "\n",
        "            messages = [{\"role\": \"system\", \"content\": self.persona}]\n",
        "            for human, ai in chat_history[-6:]:\n",
        "                if human and ai:\n",
        "                    messages.append({\"role\": \"user\", \"content\": human})\n",
        "                    messages.append({\"role\": \"assistant\", \"content\": ai})\n",
        "\n",
        "            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
        "            context_info = \"\"\n",
        "            if legal_context:\n",
        "                context_info = f\"\\n\\nğŸ“š ê´€ë ¨ ë²•ë¥  ë¬¸ì„œ:\\n{legal_context}\"\n",
        "\n",
        "            image_info = \"\"\n",
        "            if image_analysis:\n",
        "                image_info = f\"\\n\\nğŸ“¸ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼:\\n{image_analysis}\"\n",
        "\n",
        "            prompt = f\"\"\"ì‚¬ìš©ì ì§ˆë¬¸: {user_input}{image_info}{context_info}\n",
        "\n",
        "êµí†µì‚¬ê³  ì „ë¬¸ ë³€í˜¸ì‚¬ë¡œì„œ ì „ë¬¸ì ì´ê³  ì¹œê·¼í•˜ê²Œ ìƒë‹´í•´ì£¼ì„¸ìš”.\n",
        "ë‹¨, êµí†µê³¼ ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ì´ë©´ ì •ì¤‘íˆ ê±°ì ˆí•˜ì„¸ìš”.\n",
        "\n",
        "\n",
        "ğŸ¤ ìƒí™©ì— ë”°ë¼ ë‹¤ìŒ ì¶”ê°€ ì„œë¹„ìŠ¤ë¥¼ ì œì•ˆí•˜ì„¸ìš”:\n",
        "- í˜•ì‚¬ì‚¬ê±´ì‹œ ë°˜ì„±ë¬¸ ì‘ì„±ì„ ë„ì™€ì£¼ì„¸ìš”\n",
        "- ë¯¼ì‚¬ë¶„ìŸì‹œ í•©ì˜ ê´€ë ¨ëœ ì¡°ì–¸ì„ í•´ì£¼ì„¸ìš”\n",
        "- ìƒí™©ë³„ ì¦‰ì‹œ ì¡°ì¹˜ì‚¬í•­ ì•ˆë‚´í•´ ì£¼ì„¸ìš”\n",
        "\n",
        "ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ êµ¬ì²´ì  ì§ˆë¬¸ì„ í•˜ê³ , ê³¼ì‹¤ë¹„ìœ¨ê³¼ ë²•ì  ê·¼ê±°ë¥¼ ëª…í™•íˆ ì œì‹œí•˜ì„¸ìš”.\n",
        "\"\"\"\n",
        "\n",
        "            messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "            print(\"ğŸ¤– GPT-4o ì‘ë‹µ ìƒì„± ì¤‘...\")\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=\"gpt-4o\", messages=messages, temperature=0.2, max_tokens=1800\n",
        "            )\n",
        "\n",
        "            response_content = response.choices[0].message.content\n",
        "            print(\"âœ… ì‘ë‹µ ìƒì„± ì™„ë£Œ\")\n",
        "            return response_content\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"\n",
        "            print(f\"âŒ {error_msg}\")\n",
        "            return \"ì£„ì†¡í•©ë‹ˆë‹¤. ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\"\n",
        "\n",
        "def create_interface():\n",
        "    \"\"\"Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„± (ì™„ì „ ê°œì„ íŒ)\"\"\"\n",
        "    system = ChatMoonCheolSystem()\n",
        "\n",
        "    # =================================================================================\n",
        "    # âœ¨ 1ë‹¨ê³„ (ìˆ˜ì •ëœ ë¶€ë¶„): ì—¬ê¸°ì— ì•„ë°”íƒ€ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œë¥¼ ì§€ì •í•˜ì„¸ìš”.\n",
        "    # ì½”ë©ì— ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•œ í›„, íŒŒì¼ ê²½ë¡œë¥¼ ë³µì‚¬í•˜ì—¬ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.\n",
        "    # ì˜ˆì‹œ: /content/my_avatar.png\n",
        "    # =================================================================================\n",
        "    user_avatar_path = \"/content/user_17301067.png\"  # ğŸ‘ˆ ì‚¬ìš©ì í”„ë¡œí•„ ì´ë¯¸ì§€ ê²½ë¡œ\n",
        "    bot_avatar_path = \"/content/ë¬¸ì² ì´.jpg\"    # ğŸ‘ˆ ì±—ë´‡ í”„ë¡œí•„ ì´ë¯¸ì§€ ê²½ë¡œ\n",
        "\n",
        "    css = \"\"\"\n",
        "    /* ğŸ¨ ì „ì—­ ìŠ¤íƒ€ì¼ - ëª¨ë˜í•˜ê³  ë¯¸ë‹ˆë©€í•œ ë””ìì¸ */\n",
        "    .gradio-container {\n",
        "        font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;\n",
        "    }\n",
        "    /* ... (ì´í•˜ CSS ì½”ë“œëŠ” ë™ì¼) ... */\n",
        "    .login-container { max-width: 1000px; margin: 0 auto; padding: 40px; }\n",
        "    .login-header { text-align: center; padding: 40px 30px; background: linear-gradient(135deg, #3771E3 0%, #3b82f6 100%); color: white; border-radius: 20px; margin-bottom: 40px; box-shadow: 0 10px 30px rgba(102, 126, 234, 0.3); }\n",
        "    .login-header h1 { font-size: 2.5em; margin: 0 0 10px 0; font-weight: 700; color: white; }\n",
        "    .login-header h2 { font-size: 1.5em; margin: 0 0 15px 0; font-weight: 500; opacity: 0.9; color: white; }\n",
        "    .login-header h3 { color: white; font-weight: 500; opacity: 0.9; }\n",
        "    .login-header p { font-size: 1.1em; margin: 10px 0; opacity: 0.8; }\n",
        "    .login-card { background: white; border-radius: 16px; padding: 30px; box-shadow: 0 8px 25px rgba(0, 0, 0, 0.1); border: 1px solid #e9ecef; }\n",
        "    .main-header { text-align: center; padding: 25px; background: linear-gradient(135deg, #3771E3 0%, #3b82f6 100%); color: white; border-radius: 15px; margin-bottom: 25px; box-shadow: 0 8px 25px rgba(102, 126, 234, 0.2); }\n",
        "    .main-header h1 { margin: 0 0 8px 0; font-size: 2em; font-weight: 700; color: white; }\n",
        "    .main-header h2 { margin: 0; font-size: 1.2em; font-weight: 500; opacity: 0.9; color: white; }\n",
        "    .user-info { background: #ffffff; color: #4a5568; padding: 15px 20px; border-radius: 12px; margin: 15px 0; font-weight: 600; text-align: center; border: 1px solid #e9ecef; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.06); }\n",
        "    .chat-main-container { display: flex; gap: 20px; height: 85vh; padding: 15px; background: #f8f9fb; border-radius: 16px; }\n",
        "    .chat-sidebar { width: 280px; min-width: 280px; background: white; border-radius: 16px; padding: 25px; border: 1px solid #e1e5e9; box-shadow: 0 4px 20px rgba(0, 0, 0, 0.08); display: flex; flex-direction: column; gap: 20px; }\n",
        "    .icon-button { display: flex; align-items: center; justify-content: center; padding: 15px; border-radius: 16px !important; border: 2px solid #e1e5e9 !important; background: white !important; color: #4a5568 !important; font-size: 14px !important; font-weight: 600 !important; transition: all 0.3s ease !important; min-height: 60px !important; cursor: pointer !important; text-align: center !important; gap: 8px !important; }\n",
        "    .icon-button:hover { background: #f7fafc !important; border-color: #3b82f6!important; color: #3b82f6!important; transform: translateY(-2px) !important; box-shadow: 0 6px 20px rgba(102, 126, 234, 0.2) !important; }\n",
        "    .icon-button.primary { background: linear-gradient(135deg, #3771E3 0%, #3b82f6 100%) !important; color: white !important; border-color: transparent !important; }\n",
        "    .icon-button.primary:hover { transform: translateY(-2px) !important; box-shadow: 0 8px 25px rgba(102, 126, 234, 0.4) !important; }\n",
        "    .chat-main { flex: 1; display: flex; flex-direction: column; background: white; border-radius: 16px; border: 1px solid #e1e5e9; overflow: hidden; box-shadow: 0 4px 20px rgba(0, 0, 0, 0.08); }\n",
        "    .chat-header { background: linear-gradient(135deg, #3771E3 0%, #3b82f6 100%); color: white; padding: 25px; text-align: center; border-bottom: 3px solid rgba(255, 255, 255, 0.2); }\n",
        "    .chat-header h2 { margin: 0 0 8px 0; font-size: 1.6em; font-weight: 700; }\n",
        "    .chat-header p { margin: 0; opacity: 0.9; font-size: 1em; }\n",
        "    .input-area { background: #f8f9fb; padding: 25px; border-top: 1px solid #e9ecef; box-shadow: 0 -2px 10px rgba(0, 0, 0, 0.05); }\n",
        "    .send-button { background: linear-gradient(135deg, #3771E3 0%, #3b82f6 100%) !important; border: none !important; border-radius: 12px !important; color: white !important; font-weight: 600 !important; padding: 12px 20px !important; font-size: 14px !important; min-width: 100px !important; height: 100% !important; transition: all 0.3s ease !important; box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3) !important; }\n",
        "    .send-button:hover { transform: translateY(-2px) !important; box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4) !important; }\n",
        "    .admin-panel { background: linear-gradient(135deg, #ffecd2 0%, #fcb69f 100%); padding: 25px; border-radius: 16px; border: 2px solid #ed8936; margin-bottom: 25px; box-shadow: 0 8px 25px rgba(237, 137, 54, 0.2); }\n",
        "    .admin-panel h2 { color: #9c4221; margin: 0 0 10px 0; font-weight: 700; }\n",
        "    .admin-panel p { color: #744210; margin: 5px 0; font-weight: 500; }\n",
        "    .section { background: white; border-radius: 12px; padding: 20px; margin-bottom: 20px; border: 1px solid #e9ecef; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.04); }\n",
        "    .section h3 { color: #2d3748; margin: 0 0 15px 0; font-weight: 700; font-size: 1.1em; }\n",
        "    @media (max-width: 1024px) { .chat-main-container { flex-direction: column; height: auto; } .chat-sidebar { width: 100%; min-width: auto; flex-direction: row; overflow-x: auto; } .login-container { padding: 20px; } }\n",
        "    @media (max-width: 768px) { .login-header h1 { font-size: 2em; } .main-header h1 { font-size: 1.6em; } .chat-sidebar { flex-direction: column; } }\n",
        "    .user-logout-row { align-items: center !important; gap: 15px !important; }\n",
        "    \"\"\"\n",
        "\n",
        "    with gr.Blocks(theme=gr.themes.Soft(), title=\"ì±—ë¬¸ì²  ì™„ì „ ê°œì„ íŒ\", css=css) as app:\n",
        "\n",
        "        # ìƒíƒœ ê´€ë¦¬\n",
        "        current_user = gr.State(None)\n",
        "        current_messages = gr.State([])\n",
        "\n",
        "        # ğŸ” ë¡œê·¸ì¸ í˜ì´ì§€ (ê°„ì†Œí™”ë¨)\n",
        "        with gr.Column(visible=True, elem_classes=[\"login-container\"]) as login_page:\n",
        "            gr.HTML('''\n",
        "            <div class=\"login-header\">\n",
        "                <h1>ì±—ë¬¸ì² </h1>\n",
        "                <h3>êµí†µë²• AI ìƒë‹´ ì„œë¹„ìŠ¤</h3>\n",
        "            </div>\n",
        "            ''')\n",
        "\n",
        "            with gr.Tabs():\n",
        "                with gr.Tab(\"ë¡œê·¸ì¸\"):\n",
        "                    with gr.Row():\n",
        "                        with gr.Column(elem_classes=[\"login-card\"]):\n",
        "                            gr.Markdown(\"### ë¡œê·¸ì¸\")\n",
        "                            login_username = gr.Textbox(\n",
        "                                label=\"ì•„ì´ë””\",\n",
        "                                placeholder=\"ì•„ì´ë””ë¥¼ ì…ë ¥í•˜ì„¸ìš”\",\n",
        "                                container=True\n",
        "                            )\n",
        "                            login_password = gr.Textbox(\n",
        "                                label=\"ë¹„ë°€ë²ˆí˜¸\",\n",
        "                                type=\"password\",\n",
        "                                placeholder=\"ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”\",\n",
        "                                container=True\n",
        "                            )\n",
        "                            login_btn = gr.Button(\n",
        "                                \"ë¡œê·¸ì¸\",\n",
        "                                variant=\"primary\",\n",
        "                                size=\"lg\",\n",
        "                                elem_classes=[\"icon-button\", \"primary\"]\n",
        "                            )\n",
        "                            login_result = gr.Textbox(label=\"ë¡œê·¸ì¸ ê²°ê³¼\", interactive=False)\n",
        "\n",
        "                with gr.Tab(\"íšŒì›ê°€ì…\"):\n",
        "                    with gr.Row():\n",
        "                        with gr.Column(elem_classes=[\"login-card\"]):\n",
        "                            gr.Markdown(\"### âœ¨ ìƒˆ ê³„ì • ë§Œë“¤ê¸°\")\n",
        "                            reg_username = gr.Textbox(label=\"ì•„ì´ë””\")\n",
        "                            reg_password = gr.Textbox(label=\"ë¹„ë°€ë²ˆí˜¸\", type=\"password\")\n",
        "                            reg_email = gr.Textbox(label=\"ì´ë©”ì¼ (ì„ íƒ)\")\n",
        "                            reg_type = gr.Dropdown(\n",
        "                                [(\"ê²ŒìŠ¤íŠ¸\", \"guest\"), (\"ì „ë¬¸ê°€\", \"expert\")],\n",
        "                                label=\"ì‚¬ìš©ì ìœ í˜•\",\n",
        "                                value=\"guest\"\n",
        "                            )\n",
        "                            register_btn = gr.Button(\n",
        "                                \"ê°€ì…í•˜ê¸°\",\n",
        "                                variant=\"secondary\",\n",
        "                                size=\"lg\",\n",
        "                                elem_classes=[\"icon-button\"]\n",
        "                            )\n",
        "                            register_result = gr.Textbox(label=\"ê°€ì… ê²°ê³¼\", interactive=False)\n",
        "\n",
        "        # ğŸ  ë©”ì¸ ì„œë¹„ìŠ¤ í˜ì´ì§€ (ì™„ì „ ê°œì„ ë¨)\n",
        "        with gr.Column(visible=False) as main_page:\n",
        "            gr.HTML('''\n",
        "            <div class=\"main-header\">\n",
        "                <h1>ì±—ë¬¸ì² </h1>\n",
        "                <h2>êµí†µë²• AI ìƒë‹´ ì„œë¹„ìŠ¤</h2>\n",
        "            </div>\n",
        "            ''')\n",
        "\n",
        "            with gr.Tabs():\n",
        "                # ğŸ’¬ AI ìƒë‹´ íƒ­ (GPT ìŠ¤íƒ€ì¼ë¡œ ì¬ë””ìì¸)\n",
        "                with gr.Tab(\"ğŸ’¬ AI ìƒë‹´\"):\n",
        "                    with gr.Column():\n",
        "                        # ì±„íŒ…ë°•ìŠ¤ (ì „ì²´ í­ ì‚¬ìš©)\n",
        "                        chatbot = gr.Chatbot(\n",
        "                            label=\"\",\n",
        "                            show_label=False,\n",
        "                            height=400,\n",
        "                            # =================================================================================\n",
        "                            # âœ¨ 2ë‹¨ê³„ (ìˆ˜ì •ëœ ë¶€ë¶„): ê¸°ì¡´ ì´ëª¨í‹°ì½˜ ëŒ€ì‹  ìœ„ì—ì„œ ë§Œë“  ì´ë¯¸ì§€ ê²½ë¡œ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "                            # =================================================================================\n",
        "                            avatar_images=(user_avatar_path, bot_avatar_path),\n",
        "                            show_copy_button=True,\n",
        "                            bubble_full_width=False,\n",
        "                            container=False,\n",
        "                            elem_classes=[\"full-width-chat\"]\n",
        "                        )\n",
        "\n",
        "                        # ì…ë ¥ ì˜ì—­ (GPT ìŠ¤íƒ€ì¼)\n",
        "                        with gr.Row():\n",
        "                            situation_input = gr.Textbox(\n",
        "                                label=\"\",\n",
        "                                lines=3,\n",
        "                                placeholder = \"ìƒí™©ì„ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”\",\n",
        "                                show_label=False,\n",
        "                                scale=20\n",
        "                            )\n",
        "                            submit_btn = gr.Button(\n",
        "                                \"ì „ì†¡\",\n",
        "                                variant=\"primary\",\n",
        "                                scale=1,\n",
        "                                elem_classes=[\"icon-button\"]\n",
        "                            )\n",
        "                            new_chat_btn = gr.Button(\n",
        "                                \"ìƒˆ ì±„íŒ…\",\n",
        "                                variant=\"secondary\",\n",
        "                                scale=1,\n",
        "                                elem_classes=[\"icon-button\"]\n",
        "                            )\n",
        "                        with gr.Row():\n",
        "                            images = gr.File(\n",
        "                                file_count=\"multiple\",\n",
        "                                file_types=[\"image\"],\n",
        "                                label=\"ì´ë¯¸ì§€ ì²¨ë¶€\",\n",
        "                                show_label=True,\n",
        "                                height=80,\n",
        "                                container=True,\n",
        "                            )\n",
        "\n",
        "                        with gr.Accordion(\"ğŸ’¡ ìƒë‹´ íŒ\", open=False):\n",
        "                            gr.Markdown(\"\"\"\n",
        "                            êµí†µì‚¬ê³  ìƒí™©ì„ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”...\n",
        "\n",
        "                            ğŸ’¬ ì˜ˆì‹œ:\n",
        "                            â€¢ ì‹ í˜¸ëŒ€ê¸° ì¤‘ ë’¤ì—ì„œ ì¶”ëŒë‹¹í–ˆì–´ìš”\n",
        "                            â€¢ êµì°¨ë¡œ ì§ì§„ ì¤‘ ì¢ŒíšŒì „ì°¨ì™€ ì¶©ëŒ\n",
        "                            â€¢ ìŒì£¼ìš´ì „ìœ¼ë¡œ ì‚¬ê³ ë¥¼ ëƒˆìŠµë‹ˆë‹¤\n",
        "\n",
        "                            ğŸ¯ êµ¬ì²´ì ì¼ìˆ˜ë¡ ì •í™•í•œ ìƒë‹´ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤!\",\n",
        "\n",
        "                            **ğŸ¯ í•„ìˆ˜ ì •ë³´**\n",
        "                            - ì‚¬ê³  ì¼ì‹œ, ì¥ì†Œ\n",
        "                            - ìƒëŒ€ë°© ì •ë³´\n",
        "                            - ì‚¬ê³  ê²½ìœ„\n",
        "                            - ë¶€ìƒ/ì†í•´ ì •ë„\n",
        "                            \"\"\")\n",
        "\n",
        "                # ğŸ“‹ ëŒ€í™” ìš”ì•½ íƒ­\n",
        "                with gr.Tab(\"ğŸ“‹ ëŒ€í™” ìš”ì•½\"):\n",
        "                    with gr.Column(elem_classes=[\"section\"]):\n",
        "                        gr.Markdown(\"### ğŸ“Š ìƒë‹´ ìš”ì•½ ë° ë¶„ì„\")\n",
        "                        summary_btn = gr.Button(\n",
        "                            \"ìš”ì•½ ìƒì„±\",\n",
        "                            variant=\"primary\",\n",
        "                            elem_classes=[\"icon-button\", \"primary\"]\n",
        "                        )\n",
        "                        summary_output = gr.Markdown()\n",
        "\n",
        "                # ğŸ“š ë¬¸ì„œ ê´€ë¦¬ íƒ­ (ê´€ë¦¬ì ì „ìš©, ê°œì„ ë¨)\n",
        "                with gr.Tab(\"ğŸ“š ë¬¸ì„œ ê´€ë¦¬\", visible=False) as admin_docs:\n",
        "                    gr.HTML('''\n",
        "                    <div class=\"admin-panel\">\n",
        "                        <h2>ğŸ“š RAG ë¬¸ì„œ ê´€ë¦¬</h2>\n",
        "                        <p>ğŸ¯ ë²•ë¥  ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì—¬ AI ìƒë‹´ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ì„¸ìš”</p>\n",
        "                    </div>\n",
        "                    ''')\n",
        "\n",
        "                    with gr.Row():\n",
        "                        with gr.Column(elem_classes=[\"section\"]):\n",
        "                            gr.Markdown(\"### ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ\")\n",
        "                            doc_files = gr.File(\n",
        "                                file_count=\"multiple\",\n",
        "                                file_types=[\".pdf\", \".txt\", \".docx\", \".md\"],\n",
        "                                label=\"íŒŒì¼ ì—…ë¡œë“œ (ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)\",\n",
        "                                height=150\n",
        "                            )\n",
        "\n",
        "                            with gr.Row():\n",
        "                                upload_btn = gr.Button(\n",
        "                                    \"ì—…ë¡œë“œ\",\n",
        "                                    variant=\"primary\",\n",
        "                                    size=\"lg\",\n",
        "                                    elem_classes=[\"icon-button\", \"primary\"]\n",
        "                                )\n",
        "                                optimize_btn = gr.Button(\n",
        "                                    \"ìµœì í™”\",\n",
        "                                    variant=\"secondary\",\n",
        "                                    elem_classes=[\"icon-button\"]\n",
        "                                )\n",
        "\n",
        "                            upload_result = gr.Textbox(\n",
        "                                label=\"ì—…ë¡œë“œ ê²°ê³¼\",\n",
        "                                lines=10,\n",
        "                                show_copy_button=True\n",
        "                            )\n",
        "\n",
        "                        with gr.Column(elem_classes=[\"section\"]):\n",
        "                            gr.Markdown(\"### ğŸ“Š RAG ì‹œìŠ¤í…œ í˜„í™©\")\n",
        "                            rag_info_btn = gr.Button(\n",
        "                                \"ğŸ”„ ìƒˆë¡œê³ ì¹¨\",\n",
        "                                variant=\"secondary\",\n",
        "                                elem_classes=[\"icon-button\"]\n",
        "                            )\n",
        "                            rag_info_display = gr.HTML()\n",
        "\n",
        "                    with gr.Column(elem_classes=[\"section\"]):\n",
        "                        gr.Markdown(\"### ğŸ“‹ ì—…ë¡œë“œëœ ë¬¸ì„œ ëª©ë¡\")\n",
        "                        doc_refresh_btn = gr.Button(\n",
        "                            \"ğŸ”„ ë¬¸ì„œ ëª©ë¡ ìƒˆë¡œê³ ì¹¨\",\n",
        "                            variant=\"secondary\",\n",
        "                            elem_classes=[\"icon-button\"]\n",
        "                        )\n",
        "                        documents_table = gr.Dataframe(\n",
        "                            headers=[\"íŒŒì¼ëª…\", \"í˜•ì‹\", \"í¬ê¸°(bytes)\", \"ì¸ì½”ë”©\", \"ì²­í¬ìˆ˜\", \"ìƒíƒœ\", \"ì—…ë¡œë“œì¼\", \"ì—…ë¡œë”\", \"ì²˜ë¦¬ì‹œê°„\", \"í•´ì‹œ\"],\n",
        "                            label=\"ë¬¸ì„œ ê´€ë¦¬\",\n",
        "                            wrap=True\n",
        "                        )\n",
        "\n",
        "                # ğŸ‘¥ ì‚¬ìš©ì ê´€ë¦¬ íƒ­ (ê´€ë¦¬ì ì „ìš©)\n",
        "                with gr.Tab(\"ğŸ‘¥ ì‚¬ìš©ì ê´€ë¦¬\", visible=False) as admin_users:\n",
        "                    gr.HTML('''\n",
        "                    <div class=\"admin-panel\">\n",
        "                        <h2>ğŸ‘¥ ì‚¬ìš©ì ëŒ€í™” ê´€ë¦¬</h2>\n",
        "                        <p>ğŸ¯ ëª¨ë“  ì‚¬ìš©ìì˜ ìƒë‹´ ë‚´ì—­ì„ ê´€ë¦¬í•˜ê³  ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤</p>\n",
        "                    </div>\n",
        "                    ''')\n",
        "\n",
        "                    with gr.Row():\n",
        "                        refresh_btn = gr.Button(\n",
        "                            \"ğŸ”„ ëŒ€í™”ëª©ë¡ ìƒˆë¡œê³ ì¹¨\",\n",
        "                            variant=\"primary\",\n",
        "                            elem_classes=[\"icon-button\", \"primary\"]\n",
        "                        )\n",
        "                        excel_btn = gr.Button(\n",
        "                            \"ì—‘ì…€ ë‹¤ìš´ë¡œë“œ\",\n",
        "                            variant=\"secondary\",\n",
        "                            elem_classes=[\"icon-button\"]\n",
        "                        )\n",
        "\n",
        "                    conversations_table = gr.Dataframe(\n",
        "                        headers=[\"ì„¸ì…˜ID\", \"ì‚¬ìš©ì\", \"ìœ í˜•\", \"ì œëª©\", \"ì‹œì‘ì‹œê°„\", \"ë©”ì‹œì§€ìˆ˜\", \"ì‚¬ê±´ìœ í˜•\", \"ì‚¬ê³ ìœ í˜•\", \"ê³¼ì‹¤ë¹„ìœ¨\", \"ì‹¬ê°ë„\", \"ì—­í• \", \"ë²Œê¸ˆ\", \"ì§•ì—­\"],\n",
        "                        label=\"ì „ì²´ ëŒ€í™” ëª©ë¡\"\n",
        "                    )\n",
        "\n",
        "            #with gr.Row():\n",
        "             #   user_info_display = gr.HTML()\n",
        "              #  logout_btn = gr.Button(\n",
        "               #     \"ë¡œê·¸ì•„ì›ƒ\",\n",
        "                #    variant=\"secondary\",\n",
        "                 #   size=\"sm\",\n",
        "                  #  elem_classes=[\"icon-button\"]\n",
        "                #)\n",
        "            with gr.Row(elem_classes=[\"user-logout-row\"]):\n",
        "              with gr.Column(scale=7):\n",
        "                user_info_display = gr.HTML()\n",
        "\n",
        "              logout_btn = gr.Button(\n",
        "                  \"ë¡œê·¸ì•„ì›ƒ\",\n",
        "                  variant=\"secondary\",\n",
        "                  size=\"sm\",\n",
        "                  elem_classes=[\"icon-button\"],\n",
        "                  scale=1\n",
        "              )\n",
        "\n",
        "        # ğŸ¯ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ë“¤ (ê°œì„ ë¨)\n",
        "        def handle_login(username, password):\n",
        "            try:\n",
        "                success, message, user = system.login(username, password)\n",
        "                if success:\n",
        "                    admin_visible = user['user_type'] == 'admin'\n",
        "                    user_html = f'''\n",
        "                    <div class=\"user-info\">\n",
        "                         {user[\"username\"]} ({user[\"user_type\"]}) |  {user.get(\"email\", \"N/A\")}\n",
        "                    </div>\n",
        "                    '''\n",
        "                    return (gr.update(visible=False), gr.update(visible=True), user_html,\n",
        "                            gr.update(visible=admin_visible), gr.update(visible=admin_visible), \"\", user)\n",
        "                return (gr.update(visible=True), gr.update(visible=False), \"\",\n",
        "                        gr.update(visible=False), gr.update(visible=False), message, None)\n",
        "            except Exception as e:\n",
        "                return (gr.update(visible=True), gr.update(visible=False), \"\",\n",
        "                        gr.update(visible=False), gr.update(visible=False), f\"ë¡œê·¸ì¸ ì˜¤ë¥˜: {e}\", None)\n",
        "\n",
        "        def handle_register(username, password, email, user_type):\n",
        "            try:\n",
        "                success, message = system.register(username, password, user_type, email)\n",
        "                return message\n",
        "            except Exception as e:\n",
        "                return f\"íšŒì›ê°€ì… ì˜¤ë¥˜: {e}\"\n",
        "\n",
        "        def handle_logout():\n",
        "            try:\n",
        "                system.current_user = None\n",
        "                system.current_session_id = None\n",
        "                return (gr.update(visible=True), gr.update(visible=False), \"\", [], \"\", None)\n",
        "            except Exception as e:\n",
        "                return (gr.update(visible=True), gr.update(visible=False), \"\", [], f\"ë¡œê·¸ì•„ì›ƒ ì˜¤ë¥˜: {e}\", None)\n",
        "\n",
        "        def start_new_conversation():\n",
        "            try:\n",
        "                if system.current_user:\n",
        "                    system.start_conversation()\n",
        "                return [], []\n",
        "            except:\n",
        "                return [], []\n",
        "\n",
        "        def process_chat(user_input, images, chat_history):\n",
        "            if not system.current_user or not user_input.strip():\n",
        "                return chat_history, \"\"\n",
        "\n",
        "            try:\n",
        "                if not system.current_session_id:\n",
        "                    system.start_conversation()\n",
        "\n",
        "                image_analysis = \"\"\n",
        "                image_data = None\n",
        "                if images and len(images) > 0:\n",
        "                    image_analysis = system.analyze_image(images[0])\n",
        "                    try:\n",
        "                        with open(images[0].name, 'rb') as f:\n",
        "                            image_data = base64.b64encode(f.read()).decode('utf-8')\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                response = system.generate_response(user_input, chat_history, image_analysis)\n",
        "\n",
        "                system.db.save_message(system.current_session_id, \"user\", user_input, image_data=image_data)\n",
        "                system.db.save_message(system.current_session_id, \"assistant\", response)\n",
        "\n",
        "                chat_history.append([user_input, response])\n",
        "\n",
        "                # 3íšŒ ì´ìƒ ëŒ€í™”ì‹œ ë¶„ì„ ì‹¤í–‰\n",
        "                if len(chat_history) >= 3:\n",
        "                    try:\n",
        "                        print(\"ëŒ€í™” ë¶„ì„ ì‹œì‘...\")\n",
        "                        messages = []\n",
        "                        for h, a in chat_history:\n",
        "                            messages.extend([{'role': 'user', 'content': h}, {'role': 'assistant', 'content': a}])\n",
        "                        analysis = system.analyzer.analyze_conversation(messages)\n",
        "                        system.db.save_analysis(system.current_session_id, analysis)\n",
        "                        print(\"âœ… ë¶„ì„ ë° DB ì €ì¥ ì™„ë£Œ\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"âš ï¸ ë¶„ì„ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "                return chat_history, \"\"\n",
        "            except Exception as e:\n",
        "                error_msg = f\"ì˜¤ë¥˜: {str(e)}\"\n",
        "                chat_history.append([user_input, error_msg])\n",
        "                return chat_history, \"\"\n",
        "\n",
        "        def generate_summary(chat_history):\n",
        "            try:\n",
        "                if not chat_history or len(chat_history) < 2:\n",
        "                    return \"ìš”ì•½í•  ëŒ€í™”ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìµœì†Œ 2íšŒ ì´ìƒ ëŒ€í™”í•´ì£¼ì„¸ìš”.\"\n",
        "                messages = []\n",
        "                for h, a in chat_history:\n",
        "                    messages.extend([{'role': 'user', 'content': h}, {'role': 'assistant', 'content': a}])\n",
        "                analysis = system.analyzer.analyze_conversation(messages)\n",
        "                return system.analyzer.generate_summary(messages, analysis)\n",
        "            except Exception as e:\n",
        "                return f\"ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}\"\n",
        "\n",
        "        def upload_documents_improved(files):\n",
        "            \"\"\"ê°œì„ ëœ ë¬¸ì„œ ì—…ë¡œë“œ (íŒŒì¼ ìœ ì§€)\"\"\"\n",
        "            try:\n",
        "                if not system.current_user or system.current_user['user_type'] != 'admin':\n",
        "                    return \"âŒ ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.\", files\n",
        "\n",
        "                if not files:\n",
        "                    return \"âŒ ì—…ë¡œë“œí•  íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.\", files\n",
        "\n",
        "                print(f\"{len(files)}ê°œ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘...\")\n",
        "\n",
        "                results = system.rag.process_documents_parallel(\n",
        "                    files,\n",
        "                    system.current_user['id'],\n",
        "                    max_workers=4\n",
        "                )\n",
        "\n",
        "                if results['processed'] > 0:\n",
        "                    success_msg = f\"âœ… ì—…ë¡œë“œ ì™„ë£Œ!\\nğŸ“Š ì´ {results['total_files']}ê°œ ì¤‘ {results['processed']}ê°œ ì„±ê³µ, {results['failed']}ê°œ ì‹¤íŒ¨\\nğŸ“ ì´ ì²­í¬ ìˆ˜: {results['total_chunks']:,}ê°œ\\nâ±ï¸ ì´ ì²˜ë¦¬ ì‹œê°„: {results['total_processing_time']:.2f}ì´ˆ\"\n",
        "                else:\n",
        "                    success_msg = f\"âŒ ì—…ë¡œë“œ ì‹¤íŒ¨\\nì´ {results['total_files']}ê°œ íŒŒì¼ ëª¨ë‘ ì‹¤íŒ¨\"\n",
        "\n",
        "                detail_results = []\n",
        "                for result in results['results']:\n",
        "                    status = \"âœ… ì„±ê³µ\" if result['success'] else f\"âŒ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}\"\n",
        "                    chunks = f\" ({result.get('chunks', 0):,}ê°œ ì²­í¬)\" if result['success'] else \"\"\n",
        "                    size = f\" [{result.get('size', 0):,} bytes]\" if result.get('size') else \"\"\n",
        "                    encoding = f\" [ì¸ì½”ë”©: {result.get('encoding', 'unknown')}]\" if result.get('encoding') else \"\"\n",
        "                    time_info = f\" [ì²˜ë¦¬ì‹œê°„: {result.get('processing_time', 0):.2f}ì´ˆ]\" if result.get('processing_time') else \"\"\n",
        "                    detail_results.append(f\"ğŸ“„ {result['filename']}{size}{encoding}{time_info} - {status}{chunks}\")\n",
        "\n",
        "                detailed_result = success_msg + \"\\n\\n\" + \"\\n\".join(detail_results)\n",
        "\n",
        "                if results['errors']:\n",
        "                    detailed_result += f\"\\n\\nâŒ ì˜¤ë¥˜ ìƒì„¸:\\n\" + \"\\n\".join(results['errors'])\n",
        "\n",
        "                return detailed_result, files\n",
        "\n",
        "            except Exception as e:\n",
        "                error_msg = f\"ì—…ë¡œë“œ ì˜¤ë¥˜: {str(e)}\"\n",
        "                return error_msg, files\n",
        "\n",
        "        def get_rag_info():\n",
        "            \"\"\"RAG ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ\"\"\"\n",
        "            try:\n",
        "                if not system.current_user or system.current_user['user_type'] != 'admin':\n",
        "                    return '<div class=\"error-box\">âŒ ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.</div>'\n",
        "\n",
        "                info = system.rag.get_collection_info()\n",
        "\n",
        "                if 'error' in info:\n",
        "                    return f'<div class=\"error-box\">âŒ {info[\"error\"]}</div>'\n",
        "\n",
        "                status_color = \"section\" if info[\"document_count\"] > 0 else \"error-box\"\n",
        "                stats = info.get('processing_stats', {})\n",
        "\n",
        "                info_html = f'''\n",
        "                <div class=\"{status_color}\">\n",
        "                    <h3>ğŸ“Š RAG ì‹œìŠ¤í…œ í˜„í™©</h3>\n",
        "                    <p><strong>ğŸ“„ ì €ì¥ëœ ë¬¸ì„œ ì²­í¬:</strong> {info[\"document_count\"]:,}ê°œ</p>\n",
        "                    <p><strong>ğŸ—ƒï¸ ì»¬ë ‰ì…˜ëª…:</strong> {info[\"collection_name\"]}</p>\n",
        "                    <p><strong>âš¡ ìƒíƒœ:</strong> {info[\"status\"]}</p>\n",
        "                    <p><strong>ğŸ”„ ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸:</strong> {datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}</p>\n",
        "                </div>\n",
        "\n",
        "                <div class=\"section\">\n",
        "                    <h3>ğŸ“ˆ ì²˜ë¦¬ í†µê³„</h3>\n",
        "                    <p><strong>ğŸ“ ì´ ì²˜ë¦¬ íŒŒì¼:</strong> {stats.get('total_files', 0)}ê°œ</p>\n",
        "                    <p><strong>âœ… ì„±ê³µ ì²˜ë¦¬:</strong> {stats.get('processed_files', 0)}ê°œ</p>\n",
        "                    <p><strong>âŒ ì‹¤íŒ¨ ì²˜ë¦¬:</strong> {stats.get('failed_files', 0)}ê°œ</p>\n",
        "                    <p><strong>ğŸ“ ì´ ìƒì„± ì²­í¬:</strong> {stats.get('total_chunks', 0):,}ê°œ</p>\n",
        "                    <p><strong>â±ï¸ ì´ ì²˜ë¦¬ ì‹œê°„:</strong> {stats.get('processing_time', 0):.2f}ì´ˆ</p>\n",
        "                </div>\n",
        "                '''\n",
        "                return info_html\n",
        "\n",
        "            except Exception as e:\n",
        "                return f'<div class=\"error-box\">âŒ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}</div>'\n",
        "\n",
        "        def optimize_storage():\n",
        "            \"\"\"ë²¡í„° ì €ì¥ì†Œ ìµœì í™”\"\"\"\n",
        "            try:\n",
        "                if not system.current_user or system.current_user['user_type'] != 'admin':\n",
        "                    return \"âŒ ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.\"\n",
        "\n",
        "                success = system.rag.optimize_storage()\n",
        "                if success:\n",
        "                    return \"âœ… ë²¡í„° ì €ì¥ì†Œ ìµœì í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\"\n",
        "                else:\n",
        "                    return \"âš ï¸ ìµœì í™” ì¤‘ ì¼ë¶€ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\"\n",
        "\n",
        "            except Exception as e:\n",
        "                return f\"âŒ ìµœì í™” ì˜¤ë¥˜: {e}\"\n",
        "\n",
        "        def get_documents_list():\n",
        "            \"\"\"ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ\"\"\"\n",
        "            try:\n",
        "                if not system.current_user or system.current_user['user_type'] != 'admin':\n",
        "                    return []\n",
        "\n",
        "                docs = system.db.get_documents_info()\n",
        "                return [[d['filename'], d['type'], f\"{d['size']:,}\", d['encoding'],\n",
        "                         f\"{d['chunks']:,}\", d['status'], d['uploaded_at'], d['uploaded_by'],\n",
        "                         f\"{d['processing_time']:.2f}s\", d['file_hash'][:8]] for d in docs]\n",
        "            except Exception as e:\n",
        "                return []\n",
        "\n",
        "        def get_conversations():\n",
        "            try:\n",
        "                if not system.current_user or system.current_user['user_type'] != 'admin':\n",
        "                    return []\n",
        "                convs = system.db.get_admin_conversations()\n",
        "                return [[c['session_id'][:8]+\"...\", c['username'], c['user_type'], c['title'] or \"ì œëª©ì—†ìŒ\",\n",
        "                         c['started_at'], c['total_messages'], c['case_type'] or \"N/A\", c['accident_type'] or \"N/A\",\n",
        "                         c['fault_ratio'] or \"N/A\", c['severity_level'] or \"N/A\", c['party_role'] or \"N/A\",\n",
        "                         f\"{c['fine_amount'] or 0:,}ì›\", c['imprisonment_period'] or \"N/A\"] for c in convs]\n",
        "            except Exception as e:\n",
        "                return []\n",
        "\n",
        "        def export_excel():\n",
        "            try:\n",
        "                if not system.current_user or system.current_user['user_type'] != 'admin':\n",
        "                    return \"ê´€ë¦¬ì ê¶Œí•œ í•„ìš”\"\n",
        "                excel_data = system.db.export_to_excel()\n",
        "                if excel_data:\n",
        "                    filename = f\"chatmooncheol_data_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
        "                    with open(filename, 'wb') as f:\n",
        "                        f.write(excel_data)\n",
        "                    return f\"âœ… {filename} ìƒì„± ì™„ë£Œ (ëŒ€í™”ëª©ë¡ + ë¬¸ì„œëª©ë¡ í¬í•¨)\"\n",
        "                return \"âŒ ì—‘ì…€ ìƒì„± ì‹¤íŒ¨\"\n",
        "            except Exception as e:\n",
        "                return f\"ì—‘ì…€ ìƒì„± ì˜¤ë¥˜: {e}\"\n",
        "\n",
        "        # ì´ë²¤íŠ¸ ë°”ì¸ë”©\n",
        "        login_btn.click(handle_login, [login_username, login_password],\n",
        "                        [login_page, main_page, user_info_display, admin_docs, admin_users, login_result, current_user])\n",
        "        register_btn.click(handle_register, [reg_username, reg_password, reg_email, reg_type], [register_result])\n",
        "        logout_btn.click(handle_logout, outputs=[login_page, main_page, user_info_display, chatbot, login_result, current_user])\n",
        "        new_chat_btn.click(start_new_conversation, outputs=[chatbot, current_messages])\n",
        "\n",
        "        submit_btn.click(process_chat, [situation_input, images, chatbot], [chatbot, situation_input])\n",
        "        situation_input.submit(process_chat, [situation_input, images, chatbot], [chatbot, situation_input])\n",
        "\n",
        "        summary_btn.click(generate_summary, [chatbot], [summary_output])\n",
        "\n",
        "        upload_btn.click(upload_documents_improved, [doc_files], [upload_result, doc_files])\n",
        "        optimize_btn.click(optimize_storage, outputs=[upload_result])\n",
        "        rag_info_btn.click(get_rag_info, outputs=[rag_info_display])\n",
        "        doc_refresh_btn.click(get_documents_list, outputs=[documents_table])\n",
        "\n",
        "        refresh_btn.click(get_conversations, outputs=[conversations_table])\n",
        "        # excel_btn.click(export_excel, outputs=[gr.Textbox(label=\"ë‹¤ìš´ë¡œë“œ ê²°ê³¼\", visible=True)])\n",
        "\n",
        "    return app\n",
        "\n",
        "def main():\n",
        "    \"\"\"ë©”ì¸ ì‹¤í–‰ (ì™„ì „ ê°œì„ íŒ)\"\"\"\n",
        "    print(\"âš–ï¸ ì±—ë¬¸ì²  ì™„ì „ ê°œì„ íŒ ì‹œìŠ¤í…œ ì‹œì‘\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    try:\n",
        "        app = create_interface()\n",
        "        print(\"âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!\")\n",
        "        print(\"ğŸŒ ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:7860 ì ‘ì†\")\n",
        "        print()\n",
        "        print(\"ğŸ” ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ê³„ì •:\")\n",
        "        print(\"  ê²ŒìŠ¤íŠ¸: guest / guest123\")\n",
        "        print(\"  ì „ë¬¸ê°€: expert / expert123\")\n",
        "        print(\"  ê´€ë¦¬ì: admin / admin123\")\n",
        "        print()\n",
        "        print(\"ğŸ¨ ì™„ì „ ê°œì„  ì‚¬í•­:\")\n",
        "        print(\"  âœ… ëª¨ë˜í•œ í•„ë › ì•„ì´ì½˜ ë””ìì¸\")\n",
        "        print(\"  âœ… ê°„ì†Œí™”ëœ ë¡œê·¸ì¸ í˜ì´ì§€\")\n",
        "        print(\"  âœ… AI ìƒë‹´: ì‚¬ì´ë“œë°” ì•„ì´ì½˜ + ì…ë ¥/ì „ì†¡ ê°œì„ \")\n",
        "        print(\"  âœ… ë¬¸ì„œ ê´€ë¦¬: ì§„í–‰ë¥  ì‚­ì œ + íŒŒì¼ ìœ ì§€\")\n",
        "        print(\"  âœ… ë°˜ì„±ë¬¸/í•©ì˜ì¡°ì–¸ ë²„íŠ¼ ì‚­ì œ\")\n",
        "        print(\"  âœ… ì „ì²´ì ì¸ UI/UX í–¥ìƒ\")\n",
        "        print()\n",
        "\n",
        "        app.launch(server_name=\"0.0.0.0\", server_port=7860, share=True, debug=False)\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nğŸ‘‹ ì‚¬ìš©í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤!\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}\")\n",
        "        print(\"ğŸ“Œ ì˜¤ë¥˜ê°€ ì§€ì†ë˜ë©´ ë‹¤ìŒì„ í™•ì¸í•´ì£¼ì„¸ìš”:\")\n",
        "        print(\"  1. OpenAI API í‚¤ í™•ì¸\")\n",
        "        print(\"  2. í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸\")\n",
        "        print(\"  3. Python 3.8 ì´ìƒ ì‚¬ìš©\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}